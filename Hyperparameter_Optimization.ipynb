{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T15:28:56.002986Z",
     "start_time": "2020-09-19T15:28:55.372696Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T15:28:57.056711Z",
     "start_time": "2020-09-19T15:28:57.026919Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13]\n",
    "y = dataset.iloc[:, 13].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T15:28:58.803937Z",
     "start_time": "2020-09-19T15:28:58.795156Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create dummy variables\n",
    "geography=pd.get_dummies(X[\"Geography\"],drop_first=True)\n",
    "gender=pd.get_dummies(X['Gender'],drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T15:28:59.938632Z",
     "start_time": "2020-09-19T15:28:59.931169Z"
    }
   },
   "outputs": [],
   "source": [
    "## Concatenate the Data Frames\n",
    "X=pd.concat([X,geography,gender],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T15:29:00.994628Z",
     "start_time": "2020-09-19T15:29:00.987308Z"
    }
   },
   "outputs": [],
   "source": [
    "## Drop Unnecessary columns\n",
    "X=X.drop(['Geography','Gender'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T18:57:36.839832Z",
     "start_time": "2020-09-15T18:57:36.822992Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T08:38:44.564375Z",
     "start_time": "2020-09-16T08:38:44.531311Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Hyperparameter Optimization with Scikit_learn Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T15:11:21.710777Z",
     "start_time": "2020-09-15T15:11:11.491176Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Embedding, Flatten, LeakyReLU, BatchNormalization, Dropout\n",
    "from tensorflow.keras.activations import relu, sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T15:11:21.731522Z",
     "start_time": "2020-09-15T15:11:21.713191Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(layers, activation):\n",
    "    model = Sequential()\n",
    "    for i, nodes in enumerate(layers):\n",
    "        if i==0:\n",
    "            model.add(Dense(nodes,input_dim=X_train.shape[1]))\n",
    "            model.add(Activation(activation))\n",
    "            model.add(Dropout(0.3))\n",
    "        else:\n",
    "            model.add(Dense(nodes))\n",
    "            model.add(Activation(activation))\n",
    "            model.add(Dropout(0.3))\n",
    "            \n",
    "    model.add(Dense(units = 1, kernel_initializer= 'glorot_uniform', activation = 'sigmoid')) \n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T10:07:04.511118Z",
     "start_time": "2020-09-12T10:07:04.507094Z"
    }
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-12T10:57:30.111230Z",
     "start_time": "2020-09-12T10:28:21.975420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41min 18s, sys: 25min 16s, total: 1h 6min 34s\n",
      "Wall time: 29min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8554999947547912,\n",
       " {'activation': 'relu',\n",
       "  'batch_size': 128,\n",
       "  'epochs': 30,\n",
       "  'layers': (45, 30, 15)}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "layers = ([20],(21,40), (45, 30, 15))\n",
    "activations = ('sigmoid', 'relu')\n",
    "param_grid = dict(layers=layers, activation=activations, batch_size = (128, 256), epochs=[30])\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid,cv=5)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "[grid_result.best_score_,grid_result.best_params_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T09:49:25.182862Z",
     "start_time": "2020-09-15T09:49:18.019432Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install -q -U keras-tuner\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Hyperparameter Optimization with Kerastuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T18:57:48.813677Z",
     "start_time": "2020-09-15T18:57:48.806335Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(units=hp.Int('units',\n",
    "                                        min_value=32,\n",
    "                                        max_value=512,\n",
    "                                        step=32),\n",
    "                           activation='relu',input_dim=X_train.shape[1]))\n",
    "    model.add(layers.Dense(1, activation='sigmoid',kernel_initializer= 'glorot_uniform'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate',\n",
    "                      values=[1e-2, 1e-3, 1e-4])),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T18:57:49.785522Z",
     "start_time": "2020-09-15T18:57:49.556822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project my_dir/test_pro/oracle.json\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='test_pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T18:57:50.280268Z",
     "start_time": "2020-09-15T18:57:50.222982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Search space summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Default search space size: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">units (Int)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-max_value: 512</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-min_value: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-sampling: None</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-step: 32</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">learning_rate (Choice)</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-default: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-ordered: True</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-values: [0.01, 0.001, 0.0001]</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T19:02:23.109547Z",
     "start_time": "2020-09-15T18:59:54.780495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - ETA: 5:05 - loss: 0.6780 - accuracy: 0.75 - ETA: 30s - loss: 0.4778 - accuracy: 0.8250 - ETA: 22s - loss: 0.4665 - accuracy: 0.821 - ETA: 15s - loss: 0.4581 - accuracy: 0.815 - ETA: 14s - loss: 0.4585 - accuracy: 0.815 - ETA: 13s - loss: 0.4533 - accuracy: 0.818 - ETA: 13s - loss: 0.4523 - accuracy: 0.817 - ETA: 12s - loss: 0.4457 - accuracy: 0.821 - ETA: 11s - loss: 0.4419 - accuracy: 0.820 - ETA: 11s - loss: 0.4463 - accuracy: 0.820 - ETA: 11s - loss: 0.4439 - accuracy: 0.819 - ETA: 10s - loss: 0.4461 - accuracy: 0.820 - ETA: 10s - loss: 0.4470 - accuracy: 0.818 - ETA: 10s - loss: 0.4449 - accuracy: 0.818 - ETA: 9s - loss: 0.4441 - accuracy: 0.817 - ETA: 9s - loss: 0.4387 - accuracy: 0.81 - ETA: 9s - loss: 0.4357 - accuracy: 0.82 - ETA: 8s - loss: 0.4333 - accuracy: 0.82 - ETA: 8s - loss: 0.4352 - accuracy: 0.82 - ETA: 8s - loss: 0.4341 - accuracy: 0.82 - ETA: 8s - loss: 0.4311 - accuracy: 0.82 - ETA: 8s - loss: 0.4265 - accuracy: 0.82 - ETA: 8s - loss: 0.4298 - accuracy: 0.82 - ETA: 7s - loss: 0.4259 - accuracy: 0.82 - ETA: 7s - loss: 0.4238 - accuracy: 0.82 - ETA: 7s - loss: 0.4257 - accuracy: 0.82 - ETA: 7s - loss: 0.4251 - accuracy: 0.82 - ETA: 6s - loss: 0.4243 - accuracy: 0.82 - ETA: 6s - loss: 0.4243 - accuracy: 0.82 - ETA: 6s - loss: 0.4278 - accuracy: 0.82 - ETA: 6s - loss: 0.4237 - accuracy: 0.82 - ETA: 6s - loss: 0.4212 - accuracy: 0.82 - ETA: 5s - loss: 0.4202 - accuracy: 0.82 - ETA: 5s - loss: 0.4175 - accuracy: 0.82 - ETA: 4s - loss: 0.4157 - accuracy: 0.82 - ETA: 4s - loss: 0.4144 - accuracy: 0.83 - ETA: 4s - loss: 0.4133 - accuracy: 0.83 - ETA: 3s - loss: 0.4098 - accuracy: 0.83 - ETA: 3s - loss: 0.4059 - accuracy: 0.83 - ETA: 3s - loss: 0.4012 - accuracy: 0.83 - ETA: 3s - loss: 0.3984 - accuracy: 0.83 - ETA: 2s - loss: 0.3987 - accuracy: 0.83 - ETA: 2s - loss: 0.3979 - accuracy: 0.83 - ETA: 2s - loss: 0.3998 - accuracy: 0.83 - ETA: 2s - loss: 0.3964 - accuracy: 0.83 - ETA: 2s - loss: 0.3997 - accuracy: 0.83 - ETA: 2s - loss: 0.3985 - accuracy: 0.83 - ETA: 1s - loss: 0.3987 - accuracy: 0.83 - ETA: 1s - loss: 0.3981 - accuracy: 0.83 - ETA: 1s - loss: 0.3970 - accuracy: 0.83 - ETA: 1s - loss: 0.3991 - accuracy: 0.83 - ETA: 1s - loss: 0.3982 - accuracy: 0.83 - ETA: 1s - loss: 0.3999 - accuracy: 0.83 - ETA: 1s - loss: 0.4005 - accuracy: 0.83 - ETA: 1s - loss: 0.3998 - accuracy: 0.83 - ETA: 1s - loss: 0.3995 - accuracy: 0.83 - ETA: 1s - loss: 0.3988 - accuracy: 0.83 - ETA: 1s - loss: 0.3979 - accuracy: 0.83 - ETA: 1s - loss: 0.3971 - accuracy: 0.83 - ETA: 1s - loss: 0.3974 - accuracy: 0.83 - ETA: 1s - loss: 0.3988 - accuracy: 0.83 - ETA: 0s - loss: 0.3993 - accuracy: 0.83 - ETA: 0s - loss: 0.4002 - accuracy: 0.83 - ETA: 0s - loss: 0.3995 - accuracy: 0.83 - ETA: 0s - loss: 0.3989 - accuracy: 0.83 - ETA: 0s - loss: 0.3979 - accuracy: 0.83 - ETA: 0s - loss: 0.3978 - accuracy: 0.83 - ETA: 0s - loss: 0.3965 - accuracy: 0.83 - ETA: 0s - loss: 0.3979 - accuracy: 0.83 - ETA: 0s - loss: 0.3985 - accuracy: 0.83 - ETA: 0s - loss: 0.3971 - accuracy: 0.83 - ETA: 0s - loss: 0.3969 - accuracy: 0.83 - ETA: 0s - loss: 0.3967 - accuracy: 0.83 - ETA: 0s - loss: 0.3956 - accuracy: 0.83 - ETA: 0s - loss: 0.3956 - accuracy: 0.83 - ETA: 0s - loss: 0.3960 - accuracy: 0.83 - ETA: 0s - loss: 0.3957 - accuracy: 0.83 - ETA: 0s - loss: 0.3955 - accuracy: 0.83 - 7s 844us/sample - loss: 0.3931 - accuracy: 0.8361 - val_loss: 0.3685 - val_accuracy: 0.8545\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - ETA: 3s - loss: 0.5173 - accuracy: 0.75 - ETA: 15s - loss: 0.4622 - accuracy: 0.750 - ETA: 11s - loss: 0.4199 - accuracy: 0.820 - ETA: 8s - loss: 0.3996 - accuracy: 0.821 - ETA: 7s - loss: 0.3958 - accuracy: 0.82 - ETA: 7s - loss: 0.3804 - accuracy: 0.82 - ETA: 7s - loss: 0.3797 - accuracy: 0.82 - ETA: 7s - loss: 0.3885 - accuracy: 0.82 - ETA: 7s - loss: 0.3944 - accuracy: 0.82 - ETA: 6s - loss: 0.3920 - accuracy: 0.83 - ETA: 6s - loss: 0.3867 - accuracy: 0.83 - ETA: 6s - loss: 0.3860 - accuracy: 0.83 - ETA: 6s - loss: 0.3761 - accuracy: 0.84 - ETA: 6s - loss: 0.3809 - accuracy: 0.84 - ETA: 5s - loss: 0.3715 - accuracy: 0.84 - ETA: 5s - loss: 0.3733 - accuracy: 0.84 - ETA: 5s - loss: 0.3717 - accuracy: 0.84 - ETA: 5s - loss: 0.3728 - accuracy: 0.84 - ETA: 4s - loss: 0.3699 - accuracy: 0.84 - ETA: 4s - loss: 0.3735 - accuracy: 0.84 - ETA: 4s - loss: 0.3750 - accuracy: 0.84 - ETA: 3s - loss: 0.3731 - accuracy: 0.84 - ETA: 3s - loss: 0.3731 - accuracy: 0.84 - ETA: 3s - loss: 0.3746 - accuracy: 0.84 - ETA: 3s - loss: 0.3744 - accuracy: 0.84 - ETA: 3s - loss: 0.3748 - accuracy: 0.84 - ETA: 3s - loss: 0.3730 - accuracy: 0.84 - ETA: 3s - loss: 0.3719 - accuracy: 0.84 - ETA: 3s - loss: 0.3709 - accuracy: 0.84 - ETA: 3s - loss: 0.3728 - accuracy: 0.84 - ETA: 3s - loss: 0.3710 - accuracy: 0.84 - ETA: 3s - loss: 0.3721 - accuracy: 0.84 - ETA: 3s - loss: 0.3714 - accuracy: 0.84 - ETA: 2s - loss: 0.3699 - accuracy: 0.84 - ETA: 2s - loss: 0.3687 - accuracy: 0.84 - ETA: 2s - loss: 0.3684 - accuracy: 0.84 - ETA: 2s - loss: 0.3661 - accuracy: 0.84 - ETA: 2s - loss: 0.3661 - accuracy: 0.84 - ETA: 2s - loss: 0.3676 - accuracy: 0.84 - ETA: 2s - loss: 0.3693 - accuracy: 0.84 - ETA: 1s - loss: 0.3688 - accuracy: 0.84 - ETA: 1s - loss: 0.3694 - accuracy: 0.84 - ETA: 1s - loss: 0.3713 - accuracy: 0.84 - ETA: 1s - loss: 0.3710 - accuracy: 0.84 - ETA: 1s - loss: 0.3706 - accuracy: 0.84 - ETA: 1s - loss: 0.3718 - accuracy: 0.84 - ETA: 1s - loss: 0.3726 - accuracy: 0.84 - ETA: 1s - loss: 0.3727 - accuracy: 0.84 - ETA: 1s - loss: 0.3698 - accuracy: 0.84 - ETA: 1s - loss: 0.3720 - accuracy: 0.84 - ETA: 1s - loss: 0.3709 - accuracy: 0.84 - ETA: 1s - loss: 0.3705 - accuracy: 0.84 - ETA: 1s - loss: 0.3704 - accuracy: 0.84 - ETA: 1s - loss: 0.3704 - accuracy: 0.84 - ETA: 0s - loss: 0.3693 - accuracy: 0.84 - ETA: 0s - loss: 0.3686 - accuracy: 0.84 - ETA: 0s - loss: 0.3691 - accuracy: 0.84 - ETA: 0s - loss: 0.3671 - accuracy: 0.84 - ETA: 0s - loss: 0.3681 - accuracy: 0.84 - ETA: 0s - loss: 0.3697 - accuracy: 0.84 - ETA: 0s - loss: 0.3673 - accuracy: 0.84 - ETA: 0s - loss: 0.3681 - accuracy: 0.84 - ETA: 0s - loss: 0.3674 - accuracy: 0.84 - ETA: 0s - loss: 0.3657 - accuracy: 0.84 - ETA: 0s - loss: 0.3656 - accuracy: 0.84 - ETA: 0s - loss: 0.3645 - accuracy: 0.84 - 4s 496us/sample - loss: 0.3650 - accuracy: 0.8475 - val_loss: 0.3548 - val_accuracy: 0.8605\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - ETA: 7s - loss: 0.2328 - accuracy: 0.96 - ETA: 3s - loss: 0.4073 - accuracy: 0.80 - ETA: 3s - loss: 0.3924 - accuracy: 0.81 - ETA: 2s - loss: 0.3944 - accuracy: 0.82 - ETA: 2s - loss: 0.3776 - accuracy: 0.83 - ETA: 2s - loss: 0.3598 - accuracy: 0.84 - ETA: 2s - loss: 0.3690 - accuracy: 0.84 - ETA: 2s - loss: 0.3767 - accuracy: 0.83 - ETA: 2s - loss: 0.3683 - accuracy: 0.84 - ETA: 2s - loss: 0.3687 - accuracy: 0.84 - ETA: 2s - loss: 0.3652 - accuracy: 0.84 - ETA: 2s - loss: 0.3703 - accuracy: 0.84 - ETA: 2s - loss: 0.3692 - accuracy: 0.84 - ETA: 2s - loss: 0.3668 - accuracy: 0.84 - ETA: 1s - loss: 0.3579 - accuracy: 0.85 - ETA: 1s - loss: 0.3662 - accuracy: 0.84 - ETA: 1s - loss: 0.3621 - accuracy: 0.85 - ETA: 1s - loss: 0.3632 - accuracy: 0.84 - ETA: 1s - loss: 0.3599 - accuracy: 0.85 - ETA: 1s - loss: 0.3591 - accuracy: 0.85 - ETA: 1s - loss: 0.3567 - accuracy: 0.85 - ETA: 1s - loss: 0.3542 - accuracy: 0.85 - ETA: 1s - loss: 0.3516 - accuracy: 0.85 - ETA: 1s - loss: 0.3524 - accuracy: 0.85 - ETA: 1s - loss: 0.3548 - accuracy: 0.85 - ETA: 1s - loss: 0.3545 - accuracy: 0.85 - ETA: 1s - loss: 0.3538 - accuracy: 0.85 - ETA: 1s - loss: 0.3532 - accuracy: 0.85 - ETA: 1s - loss: 0.3548 - accuracy: 0.85 - ETA: 1s - loss: 0.3559 - accuracy: 0.85 - ETA: 0s - loss: 0.3597 - accuracy: 0.85 - ETA: 0s - loss: 0.3607 - accuracy: 0.85 - ETA: 0s - loss: 0.3586 - accuracy: 0.85 - ETA: 0s - loss: 0.3594 - accuracy: 0.85 - ETA: 0s - loss: 0.3580 - accuracy: 0.85 - ETA: 0s - loss: 0.3597 - accuracy: 0.85 - ETA: 0s - loss: 0.3592 - accuracy: 0.85 - ETA: 0s - loss: 0.3589 - accuracy: 0.85 - ETA: 0s - loss: 0.3573 - accuracy: 0.85 - ETA: 0s - loss: 0.3569 - accuracy: 0.85 - ETA: 0s - loss: 0.3573 - accuracy: 0.85 - ETA: 0s - loss: 0.3566 - accuracy: 0.85 - ETA: 0s - loss: 0.3562 - accuracy: 0.85 - ETA: 0s - loss: 0.3555 - accuracy: 0.85 - ETA: 0s - loss: 0.3551 - accuracy: 0.85 - ETA: 0s - loss: 0.3537 - accuracy: 0.85 - ETA: 0s - loss: 0.3532 - accuracy: 0.85 - ETA: 0s - loss: 0.3544 - accuracy: 0.85 - ETA: 0s - loss: 0.3557 - accuracy: 0.85 - 3s 366us/sample - loss: 0.3564 - accuracy: 0.8547 - val_loss: 0.3550 - val_accuracy: 0.8550\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - ETA: 3s - loss: 0.3756 - accuracy: 0.87 - ETA: 2s - loss: 0.3714 - accuracy: 0.85 - ETA: 3s - loss: 0.3913 - accuracy: 0.84 - ETA: 3s - loss: 0.3639 - accuracy: 0.86 - ETA: 4s - loss: 0.3686 - accuracy: 0.86 - ETA: 4s - loss: 0.3656 - accuracy: 0.86 - ETA: 4s - loss: 0.3503 - accuracy: 0.87 - ETA: 4s - loss: 0.3501 - accuracy: 0.87 - ETA: 4s - loss: 0.3647 - accuracy: 0.86 - ETA: 4s - loss: 0.3757 - accuracy: 0.85 - ETA: 4s - loss: 0.3689 - accuracy: 0.85 - ETA: 4s - loss: 0.3703 - accuracy: 0.85 - ETA: 3s - loss: 0.3684 - accuracy: 0.85 - ETA: 3s - loss: 0.3687 - accuracy: 0.85 - ETA: 4s - loss: 0.3762 - accuracy: 0.84 - ETA: 3s - loss: 0.3772 - accuracy: 0.84 - ETA: 3s - loss: 0.3820 - accuracy: 0.84 - ETA: 3s - loss: 0.3731 - accuracy: 0.84 - ETA: 3s - loss: 0.3679 - accuracy: 0.84 - ETA: 3s - loss: 0.3647 - accuracy: 0.84 - ETA: 2s - loss: 0.3642 - accuracy: 0.84 - ETA: 2s - loss: 0.3624 - accuracy: 0.85 - ETA: 2s - loss: 0.3668 - accuracy: 0.84 - ETA: 2s - loss: 0.3605 - accuracy: 0.85 - ETA: 2s - loss: 0.3547 - accuracy: 0.85 - ETA: 2s - loss: 0.3552 - accuracy: 0.85 - ETA: 2s - loss: 0.3567 - accuracy: 0.85 - ETA: 1s - loss: 0.3607 - accuracy: 0.84 - ETA: 1s - loss: 0.3560 - accuracy: 0.85 - ETA: 1s - loss: 0.3518 - accuracy: 0.85 - ETA: 1s - loss: 0.3504 - accuracy: 0.85 - ETA: 1s - loss: 0.3513 - accuracy: 0.85 - ETA: 1s - loss: 0.3499 - accuracy: 0.85 - ETA: 0s - loss: 0.3493 - accuracy: 0.85 - ETA: 0s - loss: 0.3494 - accuracy: 0.85 - ETA: 0s - loss: 0.3496 - accuracy: 0.85 - ETA: 0s - loss: 0.3497 - accuracy: 0.85 - ETA: 0s - loss: 0.3501 - accuracy: 0.85 - ETA: 0s - loss: 0.3510 - accuracy: 0.85 - ETA: 0s - loss: 0.3516 - accuracy: 0.85 - ETA: 0s - loss: 0.3497 - accuracy: 0.85 - 2s 308us/sample - loss: 0.3496 - accuracy: 0.8580 - val_loss: 0.3446 - val_accuracy: 0.8595\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - ETA: 4s - loss: 0.1834 - accuracy: 0.93 - ETA: 2s - loss: 0.3477 - accuracy: 0.85 - ETA: 1s - loss: 0.3155 - accuracy: 0.88 - ETA: 1s - loss: 0.3294 - accuracy: 0.86 - ETA: 1s - loss: 0.3371 - accuracy: 0.86 - ETA: 2s - loss: 0.3295 - accuracy: 0.86 - ETA: 2s - loss: 0.3336 - accuracy: 0.86 - ETA: 2s - loss: 0.3323 - accuracy: 0.86 - ETA: 2s - loss: 0.3341 - accuracy: 0.86 - ETA: 2s - loss: 0.3408 - accuracy: 0.85 - ETA: 1s - loss: 0.3406 - accuracy: 0.85 - ETA: 1s - loss: 0.3370 - accuracy: 0.85 - ETA: 1s - loss: 0.3340 - accuracy: 0.86 - ETA: 1s - loss: 0.3407 - accuracy: 0.85 - ETA: 1s - loss: 0.3357 - accuracy: 0.86 - ETA: 1s - loss: 0.3395 - accuracy: 0.85 - ETA: 1s - loss: 0.3447 - accuracy: 0.85 - ETA: 0s - loss: 0.3418 - accuracy: 0.85 - ETA: 0s - loss: 0.3430 - accuracy: 0.85 - ETA: 0s - loss: 0.3464 - accuracy: 0.85 - ETA: 0s - loss: 0.3479 - accuracy: 0.85 - ETA: 0s - loss: 0.3483 - accuracy: 0.85 - ETA: 0s - loss: 0.3496 - accuracy: 0.85 - ETA: 0s - loss: 0.3485 - accuracy: 0.85 - ETA: 0s - loss: 0.3491 - accuracy: 0.85 - ETA: 0s - loss: 0.3501 - accuracy: 0.85 - ETA: 0s - loss: 0.3489 - accuracy: 0.85 - ETA: 0s - loss: 0.3482 - accuracy: 0.85 - ETA: 0s - loss: 0.3485 - accuracy: 0.85 - ETA: 0s - loss: 0.3488 - accuracy: 0.85 - ETA: 0s - loss: 0.3487 - accuracy: 0.85 - ETA: 0s - loss: 0.3482 - accuracy: 0.85 - ETA: 0s - loss: 0.3483 - accuracy: 0.85 - ETA: 0s - loss: 0.3478 - accuracy: 0.85 - ETA: 0s - loss: 0.3480 - accuracy: 0.85 - ETA: 0s - loss: 0.3481 - accuracy: 0.85 - ETA: 0s - loss: 0.3481 - accuracy: 0.85 - 2s 296us/sample - loss: 0.3499 - accuracy: 0.8565 - val_loss: 0.3346 - val_accuracy: 0.8610\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - ETA: 3:15 - loss: 0.6640 - accuracy: 0.71 - ETA: 18s - loss: 0.5050 - accuracy: 0.7983 - ETA: 16s - loss: 0.5058 - accuracy: 0.793 - ETA: 12s - loss: 0.4766 - accuracy: 0.803 - ETA: 10s - loss: 0.4554 - accuracy: 0.809 - ETA: 9s - loss: 0.4515 - accuracy: 0.811 - ETA: 8s - loss: 0.4469 - accuracy: 0.81 - ETA: 7s - loss: 0.4610 - accuracy: 0.81 - ETA: 6s - loss: 0.4497 - accuracy: 0.81 - ETA: 5s - loss: 0.4490 - accuracy: 0.82 - ETA: 4s - loss: 0.4416 - accuracy: 0.81 - ETA: 4s - loss: 0.4406 - accuracy: 0.81 - ETA: 4s - loss: 0.4443 - accuracy: 0.81 - ETA: 4s - loss: 0.4436 - accuracy: 0.81 - ETA: 3s - loss: 0.4459 - accuracy: 0.81 - ETA: 3s - loss: 0.4427 - accuracy: 0.81 - ETA: 3s - loss: 0.4421 - accuracy: 0.81 - ETA: 3s - loss: 0.4356 - accuracy: 0.81 - ETA: 3s - loss: 0.4330 - accuracy: 0.82 - ETA: 2s - loss: 0.4299 - accuracy: 0.82 - ETA: 2s - loss: 0.4259 - accuracy: 0.82 - ETA: 2s - loss: 0.4197 - accuracy: 0.82 - ETA: 2s - loss: 0.4202 - accuracy: 0.82 - ETA: 2s - loss: 0.4194 - accuracy: 0.82 - ETA: 2s - loss: 0.4201 - accuracy: 0.82 - ETA: 2s - loss: 0.4163 - accuracy: 0.82 - ETA: 2s - loss: 0.4153 - accuracy: 0.82 - ETA: 1s - loss: 0.4100 - accuracy: 0.82 - ETA: 1s - loss: 0.4087 - accuracy: 0.82 - ETA: 1s - loss: 0.4081 - accuracy: 0.82 - ETA: 1s - loss: 0.4092 - accuracy: 0.82 - ETA: 1s - loss: 0.4084 - accuracy: 0.83 - ETA: 1s - loss: 0.4090 - accuracy: 0.83 - ETA: 1s - loss: 0.4058 - accuracy: 0.83 - ETA: 1s - loss: 0.4022 - accuracy: 0.83 - ETA: 1s - loss: 0.4039 - accuracy: 0.83 - ETA: 1s - loss: 0.4031 - accuracy: 0.83 - ETA: 1s - loss: 0.4021 - accuracy: 0.83 - ETA: 1s - loss: 0.3990 - accuracy: 0.83 - ETA: 1s - loss: 0.3969 - accuracy: 0.83 - ETA: 0s - loss: 0.3995 - accuracy: 0.83 - ETA: 0s - loss: 0.4007 - accuracy: 0.83 - ETA: 0s - loss: 0.3982 - accuracy: 0.83 - ETA: 0s - loss: 0.3965 - accuracy: 0.83 - ETA: 0s - loss: 0.3956 - accuracy: 0.83 - ETA: 0s - loss: 0.3956 - accuracy: 0.83 - ETA: 0s - loss: 0.3957 - accuracy: 0.83 - ETA: 0s - loss: 0.3951 - accuracy: 0.83 - ETA: 0s - loss: 0.3971 - accuracy: 0.83 - ETA: 0s - loss: 0.3944 - accuracy: 0.83 - ETA: 0s - loss: 0.3956 - accuracy: 0.83 - 4s 497us/sample - loss: 0.3965 - accuracy: 0.8385 - val_loss: 0.3631 - val_accuracy: 0.8510\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - ETA: 1s - loss: 0.4386 - accuracy: 0.78 - ETA: 3s - loss: 0.2878 - accuracy: 0.90 - ETA: 4s - loss: 0.3182 - accuracy: 0.88 - ETA: 2s - loss: 0.3514 - accuracy: 0.86 - ETA: 1s - loss: 0.3601 - accuracy: 0.84 - ETA: 1s - loss: 0.3403 - accuracy: 0.86 - ETA: 1s - loss: 0.3418 - accuracy: 0.86 - ETA: 0s - loss: 0.3477 - accuracy: 0.85 - ETA: 0s - loss: 0.3474 - accuracy: 0.85 - ETA: 0s - loss: 0.3416 - accuracy: 0.86 - ETA: 0s - loss: 0.3450 - accuracy: 0.85 - ETA: 0s - loss: 0.3482 - accuracy: 0.86 - ETA: 0s - loss: 0.3552 - accuracy: 0.85 - ETA: 0s - loss: 0.3562 - accuracy: 0.85 - ETA: 0s - loss: 0.3572 - accuracy: 0.85 - ETA: 0s - loss: 0.3567 - accuracy: 0.85 - ETA: 0s - loss: 0.3604 - accuracy: 0.85 - ETA: 0s - loss: 0.3593 - accuracy: 0.85 - ETA: 0s - loss: 0.3619 - accuracy: 0.85 - ETA: 0s - loss: 0.3632 - accuracy: 0.85 - ETA: 0s - loss: 0.3609 - accuracy: 0.85 - ETA: 0s - loss: 0.3609 - accuracy: 0.85 - ETA: 0s - loss: 0.3621 - accuracy: 0.85 - ETA: 0s - loss: 0.3623 - accuracy: 0.85 - ETA: 0s - loss: 0.3619 - accuracy: 0.85 - ETA: 0s - loss: 0.3606 - accuracy: 0.85 - ETA: 0s - loss: 0.3614 - accuracy: 0.85 - ETA: 0s - loss: 0.3614 - accuracy: 0.85 - ETA: 0s - loss: 0.3619 - accuracy: 0.85 - ETA: 0s - loss: 0.3630 - accuracy: 0.85 - ETA: 0s - loss: 0.3617 - accuracy: 0.85 - ETA: 0s - loss: 0.3617 - accuracy: 0.85 - ETA: 0s - loss: 0.3615 - accuracy: 0.85 - 2s 279us/sample - loss: 0.3605 - accuracy: 0.8536 - val_loss: 0.3593 - val_accuracy: 0.8440\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - ETA: 3s - loss: 0.2614 - accuracy: 0.87 - ETA: 2s - loss: 0.3392 - accuracy: 0.85 - ETA: 2s - loss: 0.3531 - accuracy: 0.85 - ETA: 2s - loss: 0.3403 - accuracy: 0.85 - ETA: 2s - loss: 0.3371 - accuracy: 0.85 - ETA: 2s - loss: 0.3441 - accuracy: 0.85 - ETA: 3s - loss: 0.3631 - accuracy: 0.84 - ETA: 2s - loss: 0.3564 - accuracy: 0.85 - ETA: 2s - loss: 0.3561 - accuracy: 0.85 - ETA: 2s - loss: 0.3546 - accuracy: 0.85 - ETA: 2s - loss: 0.3563 - accuracy: 0.85 - ETA: 2s - loss: 0.3493 - accuracy: 0.85 - ETA: 2s - loss: 0.3510 - accuracy: 0.85 - ETA: 2s - loss: 0.3510 - accuracy: 0.85 - ETA: 2s - loss: 0.3509 - accuracy: 0.85 - ETA: 2s - loss: 0.3554 - accuracy: 0.85 - ETA: 3s - loss: 0.3542 - accuracy: 0.85 - ETA: 3s - loss: 0.3570 - accuracy: 0.85 - ETA: 3s - loss: 0.3562 - accuracy: 0.85 - ETA: 2s - loss: 0.3566 - accuracy: 0.85 - ETA: 2s - loss: 0.3552 - accuracy: 0.85 - ETA: 2s - loss: 0.3557 - accuracy: 0.85 - ETA: 2s - loss: 0.3554 - accuracy: 0.85 - ETA: 2s - loss: 0.3527 - accuracy: 0.85 - ETA: 2s - loss: 0.3524 - accuracy: 0.85 - ETA: 2s - loss: 0.3533 - accuracy: 0.85 - ETA: 2s - loss: 0.3540 - accuracy: 0.85 - ETA: 2s - loss: 0.3549 - accuracy: 0.85 - ETA: 2s - loss: 0.3546 - accuracy: 0.85 - ETA: 2s - loss: 0.3564 - accuracy: 0.85 - ETA: 2s - loss: 0.3571 - accuracy: 0.85 - ETA: 2s - loss: 0.3575 - accuracy: 0.85 - ETA: 1s - loss: 0.3558 - accuracy: 0.85 - ETA: 1s - loss: 0.3510 - accuracy: 0.85 - ETA: 1s - loss: 0.3496 - accuracy: 0.85 - ETA: 1s - loss: 0.3489 - accuracy: 0.85 - ETA: 1s - loss: 0.3486 - accuracy: 0.85 - ETA: 1s - loss: 0.3478 - accuracy: 0.85 - ETA: 1s - loss: 0.3495 - accuracy: 0.85 - ETA: 1s - loss: 0.3492 - accuracy: 0.85 - ETA: 1s - loss: 0.3510 - accuracy: 0.85 - ETA: 1s - loss: 0.3511 - accuracy: 0.85 - ETA: 1s - loss: 0.3506 - accuracy: 0.85 - ETA: 1s - loss: 0.3513 - accuracy: 0.85 - ETA: 1s - loss: 0.3498 - accuracy: 0.85 - ETA: 1s - loss: 0.3509 - accuracy: 0.85 - ETA: 1s - loss: 0.3510 - accuracy: 0.85 - ETA: 1s - loss: 0.3507 - accuracy: 0.85 - ETA: 1s - loss: 0.3514 - accuracy: 0.85 - ETA: 0s - loss: 0.3519 - accuracy: 0.85 - ETA: 0s - loss: 0.3516 - accuracy: 0.85 - ETA: 0s - loss: 0.3525 - accuracy: 0.85 - ETA: 0s - loss: 0.3515 - accuracy: 0.85 - ETA: 0s - loss: 0.3523 - accuracy: 0.85 - ETA: 0s - loss: 0.3519 - accuracy: 0.85 - ETA: 0s - loss: 0.3522 - accuracy: 0.85 - ETA: 0s - loss: 0.3525 - accuracy: 0.85 - ETA: 0s - loss: 0.3540 - accuracy: 0.85 - ETA: 0s - loss: 0.3536 - accuracy: 0.85 - ETA: 0s - loss: 0.3542 - accuracy: 0.85 - ETA: 0s - loss: 0.3533 - accuracy: 0.85 - ETA: 0s - loss: 0.3531 - accuracy: 0.85 - ETA: 0s - loss: 0.3514 - accuracy: 0.85 - ETA: 0s - loss: 0.3516 - accuracy: 0.85 - ETA: 0s - loss: 0.3524 - accuracy: 0.85 - ETA: 0s - loss: 0.3524 - accuracy: 0.85 - ETA: 0s - loss: 0.3523 - accuracy: 0.85 - ETA: 0s - loss: 0.3518 - accuracy: 0.85 - ETA: 0s - loss: 0.3538 - accuracy: 0.85 - ETA: 0s - loss: 0.3535 - accuracy: 0.85 - ETA: 0s - loss: 0.3531 - accuracy: 0.85 - 4s 526us/sample - loss: 0.3532 - accuracy: 0.8547 - val_loss: 0.3494 - val_accuracy: 0.8620\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.3672 - accuracy: 0.87 - ETA: 3s - loss: 0.3352 - accuracy: 0.86 - ETA: 3s - loss: 0.3716 - accuracy: 0.84 - ETA: 4s - loss: 0.3610 - accuracy: 0.85 - ETA: 4s - loss: 0.3302 - accuracy: 0.86 - ETA: 4s - loss: 0.3567 - accuracy: 0.85 - ETA: 4s - loss: 0.3616 - accuracy: 0.84 - ETA: 4s - loss: 0.3615 - accuracy: 0.84 - ETA: 4s - loss: 0.3572 - accuracy: 0.85 - ETA: 4s - loss: 0.3459 - accuracy: 0.86 - ETA: 4s - loss: 0.3444 - accuracy: 0.85 - ETA: 4s - loss: 0.3409 - accuracy: 0.86 - ETA: 3s - loss: 0.3450 - accuracy: 0.86 - ETA: 3s - loss: 0.3502 - accuracy: 0.85 - ETA: 3s - loss: 0.3500 - accuracy: 0.85 - ETA: 3s - loss: 0.3483 - accuracy: 0.85 - ETA: 3s - loss: 0.3504 - accuracy: 0.85 - ETA: 3s - loss: 0.3494 - accuracy: 0.85 - ETA: 3s - loss: 0.3497 - accuracy: 0.85 - ETA: 3s - loss: 0.3481 - accuracy: 0.85 - ETA: 3s - loss: 0.3458 - accuracy: 0.85 - ETA: 3s - loss: 0.3553 - accuracy: 0.85 - ETA: 3s - loss: 0.3535 - accuracy: 0.85 - ETA: 2s - loss: 0.3543 - accuracy: 0.85 - ETA: 2s - loss: 0.3519 - accuracy: 0.85 - ETA: 2s - loss: 0.3527 - accuracy: 0.85 - ETA: 2s - loss: 0.3521 - accuracy: 0.85 - ETA: 2s - loss: 0.3570 - accuracy: 0.85 - ETA: 2s - loss: 0.3549 - accuracy: 0.85 - ETA: 2s - loss: 0.3532 - accuracy: 0.85 - ETA: 2s - loss: 0.3553 - accuracy: 0.85 - ETA: 2s - loss: 0.3557 - accuracy: 0.85 - ETA: 2s - loss: 0.3559 - accuracy: 0.85 - ETA: 2s - loss: 0.3564 - accuracy: 0.85 - ETA: 2s - loss: 0.3555 - accuracy: 0.85 - ETA: 2s - loss: 0.3543 - accuracy: 0.85 - ETA: 2s - loss: 0.3552 - accuracy: 0.85 - ETA: 2s - loss: 0.3558 - accuracy: 0.85 - ETA: 2s - loss: 0.3574 - accuracy: 0.85 - ETA: 2s - loss: 0.3553 - accuracy: 0.85 - ETA: 1s - loss: 0.3545 - accuracy: 0.85 - ETA: 1s - loss: 0.3532 - accuracy: 0.85 - ETA: 1s - loss: 0.3530 - accuracy: 0.85 - ETA: 1s - loss: 0.3553 - accuracy: 0.85 - ETA: 1s - loss: 0.3552 - accuracy: 0.85 - ETA: 1s - loss: 0.3547 - accuracy: 0.85 - ETA: 1s - loss: 0.3524 - accuracy: 0.85 - ETA: 1s - loss: 0.3534 - accuracy: 0.85 - ETA: 1s - loss: 0.3522 - accuracy: 0.85 - ETA: 1s - loss: 0.3530 - accuracy: 0.85 - ETA: 1s - loss: 0.3512 - accuracy: 0.85 - ETA: 1s - loss: 0.3533 - accuracy: 0.85 - ETA: 1s - loss: 0.3521 - accuracy: 0.85 - ETA: 1s - loss: 0.3528 - accuracy: 0.85 - ETA: 0s - loss: 0.3528 - accuracy: 0.85 - ETA: 0s - loss: 0.3519 - accuracy: 0.85 - ETA: 0s - loss: 0.3518 - accuracy: 0.85 - ETA: 0s - loss: 0.3521 - accuracy: 0.85 - ETA: 0s - loss: 0.3519 - accuracy: 0.85 - ETA: 0s - loss: 0.3527 - accuracy: 0.85 - ETA: 0s - loss: 0.3540 - accuracy: 0.85 - ETA: 0s - loss: 0.3529 - accuracy: 0.85 - ETA: 0s - loss: 0.3523 - accuracy: 0.85 - ETA: 0s - loss: 0.3519 - accuracy: 0.85 - ETA: 0s - loss: 0.3515 - accuracy: 0.85 - ETA: 0s - loss: 0.3509 - accuracy: 0.85 - ETA: 0s - loss: 0.3511 - accuracy: 0.85 - ETA: 0s - loss: 0.3530 - accuracy: 0.85 - ETA: 0s - loss: 0.3528 - accuracy: 0.85 - ETA: 0s - loss: 0.3529 - accuracy: 0.85 - ETA: 0s - loss: 0.3519 - accuracy: 0.85 - 4s 526us/sample - loss: 0.3519 - accuracy: 0.8547 - val_loss: 0.3450 - val_accuracy: 0.8580\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - ETA: 2s - loss: 0.2727 - accuracy: 0.87 - ETA: 3s - loss: 0.3897 - accuracy: 0.86 - ETA: 3s - loss: 0.3732 - accuracy: 0.87 - ETA: 3s - loss: 0.3576 - accuracy: 0.87 - ETA: 3s - loss: 0.3501 - accuracy: 0.87 - ETA: 3s - loss: 0.3440 - accuracy: 0.87 - ETA: 3s - loss: 0.3472 - accuracy: 0.86 - ETA: 3s - loss: 0.3375 - accuracy: 0.87 - ETA: 3s - loss: 0.3405 - accuracy: 0.86 - ETA: 3s - loss: 0.3391 - accuracy: 0.86 - ETA: 3s - loss: 0.3378 - accuracy: 0.86 - ETA: 3s - loss: 0.3355 - accuracy: 0.86 - ETA: 2s - loss: 0.3350 - accuracy: 0.86 - ETA: 2s - loss: 0.3388 - accuracy: 0.86 - ETA: 2s - loss: 0.3425 - accuracy: 0.85 - ETA: 2s - loss: 0.3411 - accuracy: 0.85 - ETA: 2s - loss: 0.3413 - accuracy: 0.86 - ETA: 2s - loss: 0.3341 - accuracy: 0.86 - ETA: 2s - loss: 0.3365 - accuracy: 0.86 - ETA: 1s - loss: 0.3424 - accuracy: 0.86 - ETA: 1s - loss: 0.3425 - accuracy: 0.86 - ETA: 1s - loss: 0.3453 - accuracy: 0.86 - ETA: 1s - loss: 0.3419 - accuracy: 0.86 - ETA: 1s - loss: 0.3426 - accuracy: 0.86 - ETA: 1s - loss: 0.3505 - accuracy: 0.85 - ETA: 1s - loss: 0.3491 - accuracy: 0.85 - ETA: 1s - loss: 0.3488 - accuracy: 0.85 - ETA: 1s - loss: 0.3519 - accuracy: 0.85 - ETA: 1s - loss: 0.3504 - accuracy: 0.85 - ETA: 1s - loss: 0.3482 - accuracy: 0.85 - ETA: 1s - loss: 0.3481 - accuracy: 0.85 - ETA: 1s - loss: 0.3465 - accuracy: 0.85 - ETA: 0s - loss: 0.3464 - accuracy: 0.85 - ETA: 0s - loss: 0.3471 - accuracy: 0.85 - ETA: 0s - loss: 0.3469 - accuracy: 0.85 - ETA: 0s - loss: 0.3456 - accuracy: 0.86 - ETA: 0s - loss: 0.3472 - accuracy: 0.85 - ETA: 0s - loss: 0.3479 - accuracy: 0.85 - ETA: 0s - loss: 0.3471 - accuracy: 0.86 - ETA: 0s - loss: 0.3463 - accuracy: 0.86 - ETA: 0s - loss: 0.3459 - accuracy: 0.86 - ETA: 0s - loss: 0.3468 - accuracy: 0.86 - ETA: 0s - loss: 0.3470 - accuracy: 0.85 - 3s 331us/sample - loss: 0.3469 - accuracy: 0.8606 - val_loss: 0.3446 - val_accuracy: 0.8640\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - ETA: 2:59 - loss: 0.6778 - accuracy: 0.65 - ETA: 14s - loss: 0.5034 - accuracy: 0.7668 - ETA: 10s - loss: 0.5031 - accuracy: 0.769 - ETA: 7s - loss: 0.4721 - accuracy: 0.788 - ETA: 5s - loss: 0.4634 - accuracy: 0.79 - ETA: 4s - loss: 0.4433 - accuracy: 0.81 - ETA: 3s - loss: 0.4488 - accuracy: 0.80 - ETA: 3s - loss: 0.4491 - accuracy: 0.80 - ETA: 2s - loss: 0.4479 - accuracy: 0.80 - ETA: 2s - loss: 0.4416 - accuracy: 0.81 - ETA: 2s - loss: 0.4367 - accuracy: 0.81 - ETA: 1s - loss: 0.4277 - accuracy: 0.82 - ETA: 1s - loss: 0.4208 - accuracy: 0.82 - ETA: 1s - loss: 0.4223 - accuracy: 0.82 - ETA: 1s - loss: 0.4209 - accuracy: 0.82 - ETA: 1s - loss: 0.4191 - accuracy: 0.82 - ETA: 1s - loss: 0.4199 - accuracy: 0.82 - ETA: 1s - loss: 0.4131 - accuracy: 0.82 - ETA: 0s - loss: 0.4099 - accuracy: 0.82 - ETA: 0s - loss: 0.4092 - accuracy: 0.82 - ETA: 0s - loss: 0.4060 - accuracy: 0.83 - ETA: 0s - loss: 0.4046 - accuracy: 0.83 - ETA: 0s - loss: 0.4027 - accuracy: 0.83 - ETA: 0s - loss: 0.4003 - accuracy: 0.83 - ETA: 0s - loss: 0.4007 - accuracy: 0.83 - ETA: 0s - loss: 0.4014 - accuracy: 0.83 - ETA: 0s - loss: 0.3988 - accuracy: 0.83 - ETA: 0s - loss: 0.3962 - accuracy: 0.83 - ETA: 0s - loss: 0.3946 - accuracy: 0.83 - ETA: 0s - loss: 0.3928 - accuracy: 0.83 - 3s 347us/sample - loss: 0.3937 - accuracy: 0.8371 - val_loss: 0.3539 - val_accuracy: 0.8510\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.3397 - accuracy: 0.84 - ETA: 2s - loss: 0.3666 - accuracy: 0.84 - ETA: 1s - loss: 0.3519 - accuracy: 0.84 - ETA: 1s - loss: 0.3573 - accuracy: 0.84 - ETA: 1s - loss: 0.3537 - accuracy: 0.85 - ETA: 1s - loss: 0.3526 - accuracy: 0.85 - ETA: 0s - loss: 0.3605 - accuracy: 0.85 - ETA: 0s - loss: 0.3618 - accuracy: 0.85 - ETA: 0s - loss: 0.3650 - accuracy: 0.85 - ETA: 0s - loss: 0.3641 - accuracy: 0.85 - ETA: 0s - loss: 0.3581 - accuracy: 0.85 - ETA: 0s - loss: 0.3589 - accuracy: 0.85 - ETA: 0s - loss: 0.3592 - accuracy: 0.85 - ETA: 0s - loss: 0.3633 - accuracy: 0.85 - ETA: 0s - loss: 0.3664 - accuracy: 0.85 - ETA: 0s - loss: 0.3682 - accuracy: 0.84 - ETA: 0s - loss: 0.3664 - accuracy: 0.84 - ETA: 0s - loss: 0.3667 - accuracy: 0.84 - ETA: 0s - loss: 0.3692 - accuracy: 0.84 - ETA: 0s - loss: 0.3702 - accuracy: 0.84 - ETA: 0s - loss: 0.3689 - accuracy: 0.84 - ETA: 0s - loss: 0.3684 - accuracy: 0.84 - ETA: 0s - loss: 0.3666 - accuracy: 0.84 - ETA: 0s - loss: 0.3676 - accuracy: 0.84 - ETA: 0s - loss: 0.3675 - accuracy: 0.84 - ETA: 0s - loss: 0.3668 - accuracy: 0.84 - ETA: 0s - loss: 0.3647 - accuracy: 0.84 - ETA: 0s - loss: 0.3652 - accuracy: 0.84 - ETA: 0s - loss: 0.3631 - accuracy: 0.85 - ETA: 0s - loss: 0.3624 - accuracy: 0.85 - 2s 225us/sample - loss: 0.3611 - accuracy: 0.8510 - val_loss: 0.3563 - val_accuracy: 0.8615\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - ETA: 2s - loss: 0.4275 - accuracy: 0.90 - ETA: 1s - loss: 0.3741 - accuracy: 0.84 - ETA: 1s - loss: 0.3384 - accuracy: 0.85 - ETA: 0s - loss: 0.3650 - accuracy: 0.83 - ETA: 0s - loss: 0.3649 - accuracy: 0.84 - ETA: 0s - loss: 0.3536 - accuracy: 0.84 - ETA: 0s - loss: 0.3567 - accuracy: 0.85 - ETA: 0s - loss: 0.3620 - accuracy: 0.84 - ETA: 0s - loss: 0.3583 - accuracy: 0.84 - ETA: 0s - loss: 0.3613 - accuracy: 0.84 - ETA: 0s - loss: 0.3612 - accuracy: 0.84 - ETA: 0s - loss: 0.3618 - accuracy: 0.84 - ETA: 0s - loss: 0.3639 - accuracy: 0.84 - ETA: 0s - loss: 0.3664 - accuracy: 0.84 - ETA: 0s - loss: 0.3646 - accuracy: 0.84 - ETA: 0s - loss: 0.3611 - accuracy: 0.85 - ETA: 0s - loss: 0.3612 - accuracy: 0.84 - ETA: 0s - loss: 0.3614 - accuracy: 0.84 - ETA: 0s - loss: 0.3579 - accuracy: 0.85 - ETA: 0s - loss: 0.3581 - accuracy: 0.85 - ETA: 0s - loss: 0.3590 - accuracy: 0.85 - ETA: 0s - loss: 0.3567 - accuracy: 0.85 - ETA: 0s - loss: 0.3579 - accuracy: 0.85 - ETA: 0s - loss: 0.3553 - accuracy: 0.85 - 1s 186us/sample - loss: 0.3555 - accuracy: 0.8553 - val_loss: 0.3616 - val_accuracy: 0.8660\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - ETA: 4s - loss: 0.3086 - accuracy: 0.84 - ETA: 1s - loss: 0.3439 - accuracy: 0.84 - ETA: 1s - loss: 0.3596 - accuracy: 0.85 - ETA: 1s - loss: 0.3683 - accuracy: 0.83 - ETA: 1s - loss: 0.3570 - accuracy: 0.84 - ETA: 1s - loss: 0.3539 - accuracy: 0.84 - ETA: 1s - loss: 0.3543 - accuracy: 0.84 - ETA: 1s - loss: 0.3584 - accuracy: 0.84 - ETA: 1s - loss: 0.3625 - accuracy: 0.84 - ETA: 1s - loss: 0.3633 - accuracy: 0.84 - ETA: 1s - loss: 0.3656 - accuracy: 0.84 - ETA: 0s - loss: 0.3613 - accuracy: 0.84 - ETA: 0s - loss: 0.3544 - accuracy: 0.84 - ETA: 0s - loss: 0.3504 - accuracy: 0.84 - ETA: 0s - loss: 0.3494 - accuracy: 0.84 - ETA: 0s - loss: 0.3493 - accuracy: 0.84 - ETA: 0s - loss: 0.3476 - accuracy: 0.84 - ETA: 0s - loss: 0.3502 - accuracy: 0.84 - ETA: 0s - loss: 0.3498 - accuracy: 0.85 - ETA: 0s - loss: 0.3483 - accuracy: 0.85 - ETA: 0s - loss: 0.3477 - accuracy: 0.85 - ETA: 0s - loss: 0.3495 - accuracy: 0.85 - ETA: 0s - loss: 0.3472 - accuracy: 0.85 - ETA: 0s - loss: 0.3479 - accuracy: 0.85 - ETA: 0s - loss: 0.3496 - accuracy: 0.85 - ETA: 0s - loss: 0.3488 - accuracy: 0.85 - ETA: 0s - loss: 0.3486 - accuracy: 0.85 - ETA: 0s - loss: 0.3503 - accuracy: 0.85 - ETA: 0s - loss: 0.3511 - accuracy: 0.85 - ETA: 0s - loss: 0.3519 - accuracy: 0.85 - ETA: 0s - loss: 0.3505 - accuracy: 0.85 - ETA: 0s - loss: 0.3511 - accuracy: 0.85 - ETA: 0s - loss: 0.3531 - accuracy: 0.85 - 2s 244us/sample - loss: 0.3523 - accuracy: 0.8543 - val_loss: 0.3401 - val_accuracy: 0.8565\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - ETA: 1s - loss: 0.1947 - accuracy: 0.93 - ETA: 3s - loss: 0.3776 - accuracy: 0.85 - ETA: 2s - loss: 0.3330 - accuracy: 0.87 - ETA: 2s - loss: 0.3466 - accuracy: 0.86 - ETA: 2s - loss: 0.3302 - accuracy: 0.87 - ETA: 1s - loss: 0.3480 - accuracy: 0.86 - ETA: 1s - loss: 0.3564 - accuracy: 0.85 - ETA: 1s - loss: 0.3601 - accuracy: 0.85 - ETA: 1s - loss: 0.3528 - accuracy: 0.86 - ETA: 1s - loss: 0.3505 - accuracy: 0.86 - ETA: 1s - loss: 0.3450 - accuracy: 0.86 - ETA: 1s - loss: 0.3464 - accuracy: 0.86 - ETA: 1s - loss: 0.3492 - accuracy: 0.86 - ETA: 1s - loss: 0.3522 - accuracy: 0.86 - ETA: 1s - loss: 0.3530 - accuracy: 0.86 - ETA: 0s - loss: 0.3507 - accuracy: 0.86 - ETA: 0s - loss: 0.3528 - accuracy: 0.85 - ETA: 0s - loss: 0.3535 - accuracy: 0.85 - ETA: 0s - loss: 0.3554 - accuracy: 0.85 - ETA: 0s - loss: 0.3528 - accuracy: 0.85 - ETA: 0s - loss: 0.3492 - accuracy: 0.85 - ETA: 0s - loss: 0.3475 - accuracy: 0.85 - ETA: 0s - loss: 0.3438 - accuracy: 0.86 - ETA: 0s - loss: 0.3447 - accuracy: 0.86 - ETA: 0s - loss: 0.3443 - accuracy: 0.86 - ETA: 0s - loss: 0.3429 - accuracy: 0.86 - ETA: 0s - loss: 0.3450 - accuracy: 0.86 - ETA: 0s - loss: 0.3467 - accuracy: 0.85 - 2s 207us/sample - loss: 0.3456 - accuracy: 0.8590 - val_loss: 0.3400 - val_accuracy: 0.8570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: e66652c49aaf734becb0b46c1d64fdae</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8636667132377625</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 320</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - ETA: 3:11 - loss: 0.6924 - accuracy: 0.62 - ETA: 12s - loss: 0.7222 - accuracy: 0.4646 - ETA: 7s - loss: 0.7050 - accuracy: 0.536 - ETA: 5s - loss: 0.6945 - accuracy: 0.55 - ETA: 3s - loss: 0.6859 - accuracy: 0.58 - ETA: 3s - loss: 0.6763 - accuracy: 0.61 - ETA: 2s - loss: 0.6639 - accuracy: 0.64 - ETA: 1s - loss: 0.6569 - accuracy: 0.65 - ETA: 1s - loss: 0.6477 - accuracy: 0.67 - ETA: 1s - loss: 0.6375 - accuracy: 0.69 - ETA: 1s - loss: 0.6324 - accuracy: 0.69 - ETA: 0s - loss: 0.6263 - accuracy: 0.70 - ETA: 0s - loss: 0.6183 - accuracy: 0.71 - ETA: 0s - loss: 0.6119 - accuracy: 0.72 - ETA: 0s - loss: 0.6067 - accuracy: 0.72 - ETA: 0s - loss: 0.6010 - accuracy: 0.73 - ETA: 0s - loss: 0.5973 - accuracy: 0.73 - ETA: 0s - loss: 0.5928 - accuracy: 0.74 - 2s 259us/sample - loss: 0.5925 - accuracy: 0.7416 - val_loss: 0.5154 - val_accuracy: 0.8065\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.5055 - accuracy: 0.81 - ETA: 1s - loss: 0.5038 - accuracy: 0.81 - ETA: 0s - loss: 0.4928 - accuracy: 0.81 - ETA: 0s - loss: 0.4962 - accuracy: 0.80 - ETA: 0s - loss: 0.4917 - accuracy: 0.80 - ETA: 0s - loss: 0.4919 - accuracy: 0.80 - ETA: 0s - loss: 0.4923 - accuracy: 0.80 - ETA: 0s - loss: 0.4953 - accuracy: 0.80 - ETA: 0s - loss: 0.4931 - accuracy: 0.80 - ETA: 0s - loss: 0.4910 - accuracy: 0.80 - ETA: 0s - loss: 0.4874 - accuracy: 0.80 - ETA: 0s - loss: 0.4901 - accuracy: 0.80 - ETA: 0s - loss: 0.4915 - accuracy: 0.80 - ETA: 0s - loss: 0.4884 - accuracy: 0.80 - ETA: 0s - loss: 0.4893 - accuracy: 0.80 - ETA: 0s - loss: 0.4860 - accuracy: 0.80 - ETA: 0s - loss: 0.4854 - accuracy: 0.80 - ETA: 0s - loss: 0.4825 - accuracy: 0.80 - 1s 138us/sample - loss: 0.4821 - accuracy: 0.8016 - val_loss: 0.4601 - val_accuracy: 0.8105\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.6062 - accuracy: 0.71 - ETA: 1s - loss: 0.4710 - accuracy: 0.79 - ETA: 0s - loss: 0.4594 - accuracy: 0.80 - ETA: 0s - loss: 0.4505 - accuracy: 0.80 - ETA: 0s - loss: 0.4464 - accuracy: 0.81 - ETA: 0s - loss: 0.4473 - accuracy: 0.81 - ETA: 0s - loss: 0.4510 - accuracy: 0.81 - ETA: 0s - loss: 0.4488 - accuracy: 0.81 - ETA: 0s - loss: 0.4460 - accuracy: 0.81 - ETA: 0s - loss: 0.4509 - accuracy: 0.80 - ETA: 0s - loss: 0.4502 - accuracy: 0.80 - ETA: 0s - loss: 0.4482 - accuracy: 0.81 - ETA: 0s - loss: 0.4482 - accuracy: 0.81 - ETA: 0s - loss: 0.4489 - accuracy: 0.80 - ETA: 0s - loss: 0.4490 - accuracy: 0.80 - ETA: 0s - loss: 0.4486 - accuracy: 0.80 - ETA: 0s - loss: 0.4496 - accuracy: 0.80 - ETA: 0s - loss: 0.4468 - accuracy: 0.80 - ETA: 0s - loss: 0.4478 - accuracy: 0.80 - 1s 146us/sample - loss: 0.4478 - accuracy: 0.8075 - val_loss: 0.4370 - val_accuracy: 0.8130\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.4245 - accuracy: 0.78 - ETA: 1s - loss: 0.4022 - accuracy: 0.82 - ETA: 1s - loss: 0.4042 - accuracy: 0.82 - ETA: 0s - loss: 0.4074 - accuracy: 0.82 - ETA: 0s - loss: 0.4100 - accuracy: 0.82 - ETA: 0s - loss: 0.4196 - accuracy: 0.81 - ETA: 0s - loss: 0.4206 - accuracy: 0.81 - ETA: 0s - loss: 0.4268 - accuracy: 0.81 - ETA: 0s - loss: 0.4287 - accuracy: 0.81 - ETA: 0s - loss: 0.4257 - accuracy: 0.81 - ETA: 0s - loss: 0.4218 - accuracy: 0.82 - ETA: 0s - loss: 0.4294 - accuracy: 0.81 - ETA: 0s - loss: 0.4309 - accuracy: 0.81 - ETA: 0s - loss: 0.4322 - accuracy: 0.81 - ETA: 0s - loss: 0.4291 - accuracy: 0.81 - ETA: 0s - loss: 0.4306 - accuracy: 0.81 - ETA: 0s - loss: 0.4300 - accuracy: 0.81 - ETA: 0s - loss: 0.4307 - accuracy: 0.81 - ETA: 0s - loss: 0.4305 - accuracy: 0.81 - 1s 145us/sample - loss: 0.4323 - accuracy: 0.8117 - val_loss: 0.4249 - val_accuracy: 0.8145\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.4639 - accuracy: 0.81 - ETA: 1s - loss: 0.4682 - accuracy: 0.80 - ETA: 1s - loss: 0.4251 - accuracy: 0.82 - ETA: 1s - loss: 0.4175 - accuracy: 0.82 - ETA: 1s - loss: 0.4223 - accuracy: 0.82 - ETA: 1s - loss: 0.4145 - accuracy: 0.82 - ETA: 1s - loss: 0.4074 - accuracy: 0.82 - ETA: 0s - loss: 0.4109 - accuracy: 0.82 - ETA: 0s - loss: 0.4122 - accuracy: 0.82 - ETA: 0s - loss: 0.4193 - accuracy: 0.81 - ETA: 0s - loss: 0.4157 - accuracy: 0.81 - ETA: 0s - loss: 0.4183 - accuracy: 0.81 - ETA: 0s - loss: 0.4186 - accuracy: 0.81 - ETA: 0s - loss: 0.4202 - accuracy: 0.81 - ETA: 0s - loss: 0.4198 - accuracy: 0.81 - ETA: 0s - loss: 0.4183 - accuracy: 0.81 - ETA: 0s - loss: 0.4165 - accuracy: 0.81 - ETA: 0s - loss: 0.4192 - accuracy: 0.81 - ETA: 0s - loss: 0.4194 - accuracy: 0.81 - ETA: 0s - loss: 0.4211 - accuracy: 0.81 - ETA: 0s - loss: 0.4225 - accuracy: 0.81 - 1s 156us/sample - loss: 0.4230 - accuracy: 0.8151 - val_loss: 0.4166 - val_accuracy: 0.8185\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - ETA: 2:48 - loss: 0.6001 - accuracy: 0.78 - ETA: 10s - loss: 0.6040 - accuracy: 0.7695 - ETA: 6s - loss: 0.6067 - accuracy: 0.759 - ETA: 4s - loss: 0.5991 - accuracy: 0.76 - ETA: 2s - loss: 0.5908 - accuracy: 0.76 - ETA: 2s - loss: 0.5822 - accuracy: 0.77 - ETA: 1s - loss: 0.5757 - accuracy: 0.78 - ETA: 1s - loss: 0.5688 - accuracy: 0.78 - ETA: 1s - loss: 0.5632 - accuracy: 0.78 - ETA: 1s - loss: 0.5548 - accuracy: 0.79 - ETA: 0s - loss: 0.5501 - accuracy: 0.79 - ETA: 0s - loss: 0.5465 - accuracy: 0.79 - ETA: 0s - loss: 0.5426 - accuracy: 0.79 - ETA: 0s - loss: 0.5393 - accuracy: 0.79 - ETA: 0s - loss: 0.5365 - accuracy: 0.79 - ETA: 0s - loss: 0.5328 - accuracy: 0.79 - ETA: 0s - loss: 0.5300 - accuracy: 0.79 - ETA: 0s - loss: 0.5266 - accuracy: 0.80 - ETA: 0s - loss: 0.5241 - accuracy: 0.80 - 2s 250us/sample - loss: 0.5230 - accuracy: 0.8009 - val_loss: 0.4742 - val_accuracy: 0.8035\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.5577 - accuracy: 0.81 - ETA: 1s - loss: 0.4583 - accuracy: 0.82 - ETA: 0s - loss: 0.4614 - accuracy: 0.81 - ETA: 0s - loss: 0.4580 - accuracy: 0.81 - ETA: 0s - loss: 0.4658 - accuracy: 0.80 - ETA: 0s - loss: 0.4694 - accuracy: 0.80 - ETA: 0s - loss: 0.4624 - accuracy: 0.81 - ETA: 0s - loss: 0.4605 - accuracy: 0.80 - ETA: 0s - loss: 0.4600 - accuracy: 0.80 - ETA: 0s - loss: 0.4619 - accuracy: 0.80 - ETA: 0s - loss: 0.4607 - accuracy: 0.80 - ETA: 0s - loss: 0.4605 - accuracy: 0.80 - ETA: 0s - loss: 0.4585 - accuracy: 0.80 - ETA: 0s - loss: 0.4596 - accuracy: 0.80 - ETA: 0s - loss: 0.4592 - accuracy: 0.80 - ETA: 0s - loss: 0.4632 - accuracy: 0.80 - ETA: 0s - loss: 0.4642 - accuracy: 0.80 - ETA: 0s - loss: 0.4640 - accuracy: 0.80 - ETA: 0s - loss: 0.4619 - accuracy: 0.80 - ETA: 0s - loss: 0.4620 - accuracy: 0.80 - ETA: 0s - loss: 0.4590 - accuracy: 0.80 - 1s 154us/sample - loss: 0.4571 - accuracy: 0.8033 - val_loss: 0.4421 - val_accuracy: 0.8125\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.5048 - accuracy: 0.84 - ETA: 1s - loss: 0.4740 - accuracy: 0.80 - ETA: 1s - loss: 0.4489 - accuracy: 0.82 - ETA: 1s - loss: 0.4517 - accuracy: 0.80 - ETA: 1s - loss: 0.4348 - accuracy: 0.82 - ETA: 1s - loss: 0.4383 - accuracy: 0.81 - ETA: 0s - loss: 0.4380 - accuracy: 0.81 - ETA: 0s - loss: 0.4387 - accuracy: 0.81 - ETA: 0s - loss: 0.4362 - accuracy: 0.81 - ETA: 0s - loss: 0.4320 - accuracy: 0.81 - ETA: 0s - loss: 0.4285 - accuracy: 0.81 - ETA: 0s - loss: 0.4351 - accuracy: 0.81 - ETA: 0s - loss: 0.4335 - accuracy: 0.81 - ETA: 0s - loss: 0.4361 - accuracy: 0.80 - ETA: 0s - loss: 0.4393 - accuracy: 0.80 - ETA: 0s - loss: 0.4389 - accuracy: 0.80 - ETA: 0s - loss: 0.4384 - accuracy: 0.80 - ETA: 0s - loss: 0.4357 - accuracy: 0.81 - ETA: 0s - loss: 0.4346 - accuracy: 0.81 - ETA: 0s - loss: 0.4371 - accuracy: 0.80 - 1s 149us/sample - loss: 0.4363 - accuracy: 0.8102 - val_loss: 0.4269 - val_accuracy: 0.8190\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.4438 - accuracy: 0.81 - ETA: 1s - loss: 0.4230 - accuracy: 0.81 - ETA: 0s - loss: 0.4378 - accuracy: 0.81 - ETA: 0s - loss: 0.4367 - accuracy: 0.81 - ETA: 0s - loss: 0.4425 - accuracy: 0.80 - ETA: 0s - loss: 0.4347 - accuracy: 0.81 - ETA: 0s - loss: 0.4311 - accuracy: 0.81 - ETA: 0s - loss: 0.4300 - accuracy: 0.81 - ETA: 0s - loss: 0.4303 - accuracy: 0.81 - ETA: 0s - loss: 0.4336 - accuracy: 0.81 - ETA: 0s - loss: 0.4338 - accuracy: 0.81 - ETA: 0s - loss: 0.4307 - accuracy: 0.81 - ETA: 0s - loss: 0.4286 - accuracy: 0.81 - ETA: 0s - loss: 0.4283 - accuracy: 0.81 - ETA: 0s - loss: 0.4282 - accuracy: 0.81 - ETA: 0s - loss: 0.4298 - accuracy: 0.81 - ETA: 0s - loss: 0.4293 - accuracy: 0.81 - ETA: 0s - loss: 0.4289 - accuracy: 0.81 - ETA: 0s - loss: 0.4297 - accuracy: 0.81 - ETA: 0s - loss: 0.4299 - accuracy: 0.81 - ETA: 0s - loss: 0.4283 - accuracy: 0.81 - ETA: 0s - loss: 0.4276 - accuracy: 0.81 - ETA: 0s - loss: 0.4269 - accuracy: 0.81 - ETA: 0s - loss: 0.4265 - accuracy: 0.81 - ETA: 0s - loss: 0.4255 - accuracy: 0.81 - 2s 190us/sample - loss: 0.4254 - accuracy: 0.8175 - val_loss: 0.4180 - val_accuracy: 0.8245\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - ETA: 4s - loss: 0.1964 - accuracy: 0.96 - ETA: 1s - loss: 0.3961 - accuracy: 0.82 - ETA: 1s - loss: 0.4156 - accuracy: 0.82 - ETA: 1s - loss: 0.4145 - accuracy: 0.82 - ETA: 1s - loss: 0.4031 - accuracy: 0.83 - ETA: 1s - loss: 0.4150 - accuracy: 0.82 - ETA: 1s - loss: 0.4191 - accuracy: 0.82 - ETA: 1s - loss: 0.4213 - accuracy: 0.82 - ETA: 1s - loss: 0.4198 - accuracy: 0.81 - ETA: 1s - loss: 0.4229 - accuracy: 0.81 - ETA: 1s - loss: 0.4197 - accuracy: 0.82 - ETA: 1s - loss: 0.4198 - accuracy: 0.82 - ETA: 0s - loss: 0.4207 - accuracy: 0.82 - ETA: 0s - loss: 0.4211 - accuracy: 0.82 - ETA: 0s - loss: 0.4219 - accuracy: 0.82 - ETA: 0s - loss: 0.4210 - accuracy: 0.82 - ETA: 0s - loss: 0.4194 - accuracy: 0.82 - ETA: 0s - loss: 0.4154 - accuracy: 0.82 - ETA: 0s - loss: 0.4163 - accuracy: 0.82 - ETA: 0s - loss: 0.4179 - accuracy: 0.82 - ETA: 0s - loss: 0.4183 - accuracy: 0.82 - ETA: 0s - loss: 0.4186 - accuracy: 0.82 - ETA: 0s - loss: 0.4196 - accuracy: 0.82 - ETA: 0s - loss: 0.4174 - accuracy: 0.82 - ETA: 0s - loss: 0.4164 - accuracy: 0.82 - ETA: 0s - loss: 0.4162 - accuracy: 0.82 - ETA: 0s - loss: 0.4169 - accuracy: 0.82 - ETA: 0s - loss: 0.4180 - accuracy: 0.82 - ETA: 0s - loss: 0.4182 - accuracy: 0.82 - ETA: 0s - loss: 0.4194 - accuracy: 0.82 - ETA: 0s - loss: 0.4204 - accuracy: 0.82 - ETA: 0s - loss: 0.4188 - accuracy: 0.82 - ETA: 0s - loss: 0.4178 - accuracy: 0.82 - ETA: 0s - loss: 0.4184 - accuracy: 0.82 - 2s 248us/sample - loss: 0.4180 - accuracy: 0.8213 - val_loss: 0.4113 - val_accuracy: 0.8245\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - ETA: 2:49 - loss: 0.7056 - accuracy: 0.53 - ETA: 15s - loss: 0.7670 - accuracy: 0.3324 - ETA: 8s - loss: 0.7610 - accuracy: 0.340 - ETA: 6s - loss: 0.7575 - accuracy: 0.34 - ETA: 5s - loss: 0.7505 - accuracy: 0.36 - ETA: 4s - loss: 0.7418 - accuracy: 0.38 - ETA: 3s - loss: 0.7397 - accuracy: 0.39 - ETA: 3s - loss: 0.7383 - accuracy: 0.39 - ETA: 3s - loss: 0.7343 - accuracy: 0.40 - ETA: 3s - loss: 0.7315 - accuracy: 0.42 - ETA: 3s - loss: 0.7264 - accuracy: 0.43 - ETA: 2s - loss: 0.7200 - accuracy: 0.45 - ETA: 2s - loss: 0.7146 - accuracy: 0.46 - ETA: 2s - loss: 0.7099 - accuracy: 0.48 - ETA: 2s - loss: 0.7055 - accuracy: 0.49 - ETA: 1s - loss: 0.7003 - accuracy: 0.51 - ETA: 1s - loss: 0.6959 - accuracy: 0.52 - ETA: 1s - loss: 0.6913 - accuracy: 0.53 - ETA: 1s - loss: 0.6861 - accuracy: 0.55 - ETA: 1s - loss: 0.6837 - accuracy: 0.56 - ETA: 1s - loss: 0.6808 - accuracy: 0.57 - ETA: 1s - loss: 0.6766 - accuracy: 0.58 - ETA: 0s - loss: 0.6712 - accuracy: 0.59 - ETA: 0s - loss: 0.6639 - accuracy: 0.61 - ETA: 0s - loss: 0.6596 - accuracy: 0.62 - ETA: 0s - loss: 0.6567 - accuracy: 0.62 - ETA: 0s - loss: 0.6525 - accuracy: 0.63 - ETA: 0s - loss: 0.6494 - accuracy: 0.64 - ETA: 0s - loss: 0.6479 - accuracy: 0.64 - ETA: 0s - loss: 0.6454 - accuracy: 0.64 - ETA: 0s - loss: 0.6420 - accuracy: 0.65 - ETA: 0s - loss: 0.6405 - accuracy: 0.65 - ETA: 0s - loss: 0.6378 - accuracy: 0.65 - ETA: 0s - loss: 0.6356 - accuracy: 0.66 - 3s 367us/sample - loss: 0.6338 - accuracy: 0.6654 - val_loss: 0.5342 - val_accuracy: 0.8090\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.5183 - accuracy: 0.81 - ETA: 1s - loss: 0.5321 - accuracy: 0.80 - ETA: 1s - loss: 0.5429 - accuracy: 0.79 - ETA: 1s - loss: 0.5376 - accuracy: 0.79 - ETA: 1s - loss: 0.5351 - accuracy: 0.79 - ETA: 1s - loss: 0.5315 - accuracy: 0.79 - ETA: 1s - loss: 0.5264 - accuracy: 0.80 - ETA: 0s - loss: 0.5243 - accuracy: 0.79 - ETA: 0s - loss: 0.5222 - accuracy: 0.79 - ETA: 1s - loss: 0.5235 - accuracy: 0.79 - ETA: 1s - loss: 0.5179 - accuracy: 0.80 - ETA: 1s - loss: 0.5162 - accuracy: 0.80 - ETA: 1s - loss: 0.5157 - accuracy: 0.80 - ETA: 1s - loss: 0.5121 - accuracy: 0.80 - ETA: 0s - loss: 0.5122 - accuracy: 0.80 - ETA: 0s - loss: 0.5111 - accuracy: 0.80 - ETA: 0s - loss: 0.5109 - accuracy: 0.80 - ETA: 0s - loss: 0.5098 - accuracy: 0.80 - ETA: 0s - loss: 0.5069 - accuracy: 0.80 - ETA: 0s - loss: 0.5026 - accuracy: 0.80 - ETA: 0s - loss: 0.5006 - accuracy: 0.80 - ETA: 0s - loss: 0.4999 - accuracy: 0.80 - ETA: 0s - loss: 0.5008 - accuracy: 0.80 - ETA: 0s - loss: 0.5009 - accuracy: 0.80 - ETA: 0s - loss: 0.5010 - accuracy: 0.80 - ETA: 0s - loss: 0.4992 - accuracy: 0.80 - ETA: 0s - loss: 0.4992 - accuracy: 0.80 - ETA: 0s - loss: 0.4977 - accuracy: 0.80 - ETA: 0s - loss: 0.4965 - accuracy: 0.80 - ETA: 0s - loss: 0.4966 - accuracy: 0.80 - ETA: 0s - loss: 0.4934 - accuracy: 0.80 - 2s 223us/sample - loss: 0.4937 - accuracy: 0.8015 - val_loss: 0.4633 - val_accuracy: 0.8070\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.4229 - accuracy: 0.87 - ETA: 2s - loss: 0.4721 - accuracy: 0.80 - ETA: 2s - loss: 0.4661 - accuracy: 0.81 - ETA: 2s - loss: 0.4799 - accuracy: 0.79 - ETA: 1s - loss: 0.4774 - accuracy: 0.79 - ETA: 1s - loss: 0.4793 - accuracy: 0.78 - ETA: 1s - loss: 0.4722 - accuracy: 0.79 - ETA: 1s - loss: 0.4709 - accuracy: 0.79 - ETA: 1s - loss: 0.4715 - accuracy: 0.79 - ETA: 1s - loss: 0.4693 - accuracy: 0.79 - ETA: 1s - loss: 0.4661 - accuracy: 0.80 - ETA: 1s - loss: 0.4698 - accuracy: 0.79 - ETA: 1s - loss: 0.4685 - accuracy: 0.79 - ETA: 1s - loss: 0.4680 - accuracy: 0.79 - ETA: 1s - loss: 0.4684 - accuracy: 0.79 - ETA: 0s - loss: 0.4642 - accuracy: 0.80 - ETA: 0s - loss: 0.4644 - accuracy: 0.80 - ETA: 0s - loss: 0.4614 - accuracy: 0.80 - ETA: 0s - loss: 0.4617 - accuracy: 0.80 - ETA: 0s - loss: 0.4619 - accuracy: 0.80 - ETA: 0s - loss: 0.4592 - accuracy: 0.80 - ETA: 0s - loss: 0.4591 - accuracy: 0.80 - ETA: 0s - loss: 0.4580 - accuracy: 0.80 - ETA: 0s - loss: 0.4570 - accuracy: 0.80 - ETA: 0s - loss: 0.4575 - accuracy: 0.80 - ETA: 0s - loss: 0.4561 - accuracy: 0.80 - ETA: 0s - loss: 0.4547 - accuracy: 0.80 - ETA: 0s - loss: 0.4535 - accuracy: 0.80 - ETA: 0s - loss: 0.4523 - accuracy: 0.80 - ETA: 0s - loss: 0.4513 - accuracy: 0.80 - 2s 221us/sample - loss: 0.4509 - accuracy: 0.8073 - val_loss: 0.4372 - val_accuracy: 0.8135\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - ETA: 1s - loss: 0.4024 - accuracy: 0.84 - ETA: 1s - loss: 0.4519 - accuracy: 0.80 - ETA: 1s - loss: 0.4588 - accuracy: 0.80 - ETA: 1s - loss: 0.4439 - accuracy: 0.81 - ETA: 1s - loss: 0.4485 - accuracy: 0.80 - ETA: 1s - loss: 0.4477 - accuracy: 0.81 - ETA: 1s - loss: 0.4506 - accuracy: 0.80 - ETA: 1s - loss: 0.4502 - accuracy: 0.80 - ETA: 1s - loss: 0.4508 - accuracy: 0.80 - ETA: 1s - loss: 0.4587 - accuracy: 0.79 - ETA: 1s - loss: 0.4559 - accuracy: 0.79 - ETA: 1s - loss: 0.4526 - accuracy: 0.80 - ETA: 0s - loss: 0.4485 - accuracy: 0.80 - ETA: 0s - loss: 0.4438 - accuracy: 0.80 - ETA: 0s - loss: 0.4427 - accuracy: 0.80 - ETA: 0s - loss: 0.4417 - accuracy: 0.80 - ETA: 0s - loss: 0.4401 - accuracy: 0.80 - ETA: 0s - loss: 0.4420 - accuracy: 0.80 - ETA: 0s - loss: 0.4392 - accuracy: 0.80 - ETA: 0s - loss: 0.4388 - accuracy: 0.80 - ETA: 0s - loss: 0.4380 - accuracy: 0.80 - ETA: 0s - loss: 0.4384 - accuracy: 0.80 - ETA: 0s - loss: 0.4358 - accuracy: 0.81 - ETA: 0s - loss: 0.4376 - accuracy: 0.81 - ETA: 0s - loss: 0.4358 - accuracy: 0.81 - ETA: 0s - loss: 0.4337 - accuracy: 0.81 - ETA: 0s - loss: 0.4321 - accuracy: 0.81 - 2s 198us/sample - loss: 0.4329 - accuracy: 0.8127 - val_loss: 0.4242 - val_accuracy: 0.8195\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - ETA: 3s - loss: 0.5611 - accuracy: 0.65 - ETA: 1s - loss: 0.4341 - accuracy: 0.81 - ETA: 1s - loss: 0.4142 - accuracy: 0.82 - ETA: 1s - loss: 0.4110 - accuracy: 0.82 - ETA: 0s - loss: 0.4122 - accuracy: 0.82 - ETA: 0s - loss: 0.4143 - accuracy: 0.82 - ETA: 0s - loss: 0.4152 - accuracy: 0.82 - ETA: 0s - loss: 0.4171 - accuracy: 0.82 - ETA: 0s - loss: 0.4176 - accuracy: 0.82 - ETA: 0s - loss: 0.4225 - accuracy: 0.81 - ETA: 0s - loss: 0.4221 - accuracy: 0.81 - ETA: 0s - loss: 0.4200 - accuracy: 0.82 - ETA: 0s - loss: 0.4202 - accuracy: 0.81 - ETA: 0s - loss: 0.4201 - accuracy: 0.82 - ETA: 0s - loss: 0.4217 - accuracy: 0.81 - ETA: 0s - loss: 0.4214 - accuracy: 0.81 - ETA: 0s - loss: 0.4237 - accuracy: 0.81 - ETA: 0s - loss: 0.4243 - accuracy: 0.81 - ETA: 0s - loss: 0.4250 - accuracy: 0.81 - ETA: 0s - loss: 0.4254 - accuracy: 0.81 - ETA: 0s - loss: 0.4258 - accuracy: 0.81 - ETA: 0s - loss: 0.4247 - accuracy: 0.81 - ETA: 0s - loss: 0.4243 - accuracy: 0.81 - ETA: 0s - loss: 0.4245 - accuracy: 0.81 - ETA: 0s - loss: 0.4235 - accuracy: 0.81 - ETA: 0s - loss: 0.4239 - accuracy: 0.81 - ETA: 0s - loss: 0.4233 - accuracy: 0.81 - 2s 194us/sample - loss: 0.4229 - accuracy: 0.8180 - val_loss: 0.4160 - val_accuracy: 0.8220\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 1a6bcac7df851bfb0c8f8e3e92bb5ba8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8216667175292969</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - ETA: 2:54 - loss: 0.6700 - accuracy: 0.59 - ETA: 14s - loss: 0.6155 - accuracy: 0.7083 - ETA: 10s - loss: 0.5725 - accuracy: 0.756 - ETA: 6s - loss: 0.5421 - accuracy: 0.768 - ETA: 4s - loss: 0.5164 - accuracy: 0.78 - ETA: 4s - loss: 0.5042 - accuracy: 0.78 - ETA: 3s - loss: 0.4833 - accuracy: 0.79 - ETA: 2s - loss: 0.4757 - accuracy: 0.80 - ETA: 2s - loss: 0.4672 - accuracy: 0.80 - ETA: 1s - loss: 0.4646 - accuracy: 0.80 - ETA: 1s - loss: 0.4664 - accuracy: 0.80 - ETA: 1s - loss: 0.4645 - accuracy: 0.80 - ETA: 1s - loss: 0.4637 - accuracy: 0.79 - ETA: 1s - loss: 0.4617 - accuracy: 0.80 - ETA: 1s - loss: 0.4614 - accuracy: 0.80 - ETA: 1s - loss: 0.4611 - accuracy: 0.80 - ETA: 1s - loss: 0.4573 - accuracy: 0.80 - ETA: 0s - loss: 0.4537 - accuracy: 0.80 - ETA: 0s - loss: 0.4492 - accuracy: 0.80 - ETA: 0s - loss: 0.4478 - accuracy: 0.80 - ETA: 0s - loss: 0.4458 - accuracy: 0.80 - ETA: 0s - loss: 0.4435 - accuracy: 0.80 - ETA: 0s - loss: 0.4423 - accuracy: 0.80 - ETA: 0s - loss: 0.4414 - accuracy: 0.81 - ETA: 0s - loss: 0.4398 - accuracy: 0.81 - ETA: 0s - loss: 0.4405 - accuracy: 0.81 - ETA: 0s - loss: 0.4381 - accuracy: 0.81 - ETA: 0s - loss: 0.4363 - accuracy: 0.81 - ETA: 0s - loss: 0.4354 - accuracy: 0.81 - ETA: 0s - loss: 0.4338 - accuracy: 0.81 - ETA: 0s - loss: 0.4343 - accuracy: 0.81 - ETA: 0s - loss: 0.4346 - accuracy: 0.81 - ETA: 0s - loss: 0.4332 - accuracy: 0.81 - 3s 360us/sample - loss: 0.4330 - accuracy: 0.8140 - val_loss: 0.3864 - val_accuracy: 0.8430\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - ETA: 3s - loss: 0.2729 - accuracy: 0.96 - ETA: 1s - loss: 0.3716 - accuracy: 0.84 - ETA: 1s - loss: 0.3791 - accuracy: 0.83 - ETA: 1s - loss: 0.3768 - accuracy: 0.83 - ETA: 1s - loss: 0.3826 - accuracy: 0.83 - ETA: 1s - loss: 0.3830 - accuracy: 0.83 - ETA: 1s - loss: 0.3779 - accuracy: 0.83 - ETA: 1s - loss: 0.3858 - accuracy: 0.83 - ETA: 1s - loss: 0.3832 - accuracy: 0.83 - ETA: 1s - loss: 0.3789 - accuracy: 0.83 - ETA: 1s - loss: 0.3826 - accuracy: 0.83 - ETA: 0s - loss: 0.3887 - accuracy: 0.83 - ETA: 0s - loss: 0.3875 - accuracy: 0.83 - ETA: 0s - loss: 0.3847 - accuracy: 0.83 - ETA: 0s - loss: 0.3856 - accuracy: 0.83 - ETA: 0s - loss: 0.3835 - accuracy: 0.83 - ETA: 0s - loss: 0.3817 - accuracy: 0.83 - ETA: 0s - loss: 0.3810 - accuracy: 0.83 - ETA: 0s - loss: 0.3851 - accuracy: 0.83 - ETA: 0s - loss: 0.3854 - accuracy: 0.83 - ETA: 0s - loss: 0.3852 - accuracy: 0.84 - ETA: 0s - loss: 0.3819 - accuracy: 0.84 - ETA: 0s - loss: 0.3790 - accuracy: 0.84 - ETA: 0s - loss: 0.3781 - accuracy: 0.84 - ETA: 0s - loss: 0.3764 - accuracy: 0.84 - 2s 196us/sample - loss: 0.3766 - accuracy: 0.8436 - val_loss: 0.3596 - val_accuracy: 0.8550\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - ETA: 3s - loss: 0.4022 - accuracy: 0.81 - ETA: 1s - loss: 0.3479 - accuracy: 0.86 - ETA: 1s - loss: 0.3675 - accuracy: 0.84 - ETA: 1s - loss: 0.3537 - accuracy: 0.85 - ETA: 1s - loss: 0.3478 - accuracy: 0.86 - ETA: 1s - loss: 0.3436 - accuracy: 0.86 - ETA: 0s - loss: 0.3453 - accuracy: 0.85 - ETA: 0s - loss: 0.3451 - accuracy: 0.85 - ETA: 0s - loss: 0.3483 - accuracy: 0.85 - ETA: 0s - loss: 0.3477 - accuracy: 0.85 - ETA: 0s - loss: 0.3509 - accuracy: 0.85 - ETA: 0s - loss: 0.3490 - accuracy: 0.85 - ETA: 0s - loss: 0.3518 - accuracy: 0.85 - ETA: 0s - loss: 0.3528 - accuracy: 0.85 - ETA: 0s - loss: 0.3527 - accuracy: 0.85 - ETA: 0s - loss: 0.3534 - accuracy: 0.85 - ETA: 0s - loss: 0.3542 - accuracy: 0.85 - ETA: 0s - loss: 0.3576 - accuracy: 0.85 - ETA: 0s - loss: 0.3559 - accuracy: 0.85 - ETA: 0s - loss: 0.3559 - accuracy: 0.85 - ETA: 0s - loss: 0.3558 - accuracy: 0.85 - ETA: 0s - loss: 0.3557 - accuracy: 0.85 - ETA: 0s - loss: 0.3558 - accuracy: 0.85 - 1s 177us/sample - loss: 0.3558 - accuracy: 0.8549 - val_loss: 0.3470 - val_accuracy: 0.8635\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - ETA: 3s - loss: 0.4598 - accuracy: 0.90 - ETA: 1s - loss: 0.3276 - accuracy: 0.88 - ETA: 1s - loss: 0.3507 - accuracy: 0.85 - ETA: 1s - loss: 0.3736 - accuracy: 0.84 - ETA: 1s - loss: 0.3671 - accuracy: 0.84 - ETA: 1s - loss: 0.3534 - accuracy: 0.85 - ETA: 1s - loss: 0.3496 - accuracy: 0.85 - ETA: 0s - loss: 0.3493 - accuracy: 0.85 - ETA: 0s - loss: 0.3434 - accuracy: 0.85 - ETA: 0s - loss: 0.3500 - accuracy: 0.85 - ETA: 0s - loss: 0.3508 - accuracy: 0.85 - ETA: 0s - loss: 0.3543 - accuracy: 0.85 - ETA: 0s - loss: 0.3530 - accuracy: 0.85 - ETA: 0s - loss: 0.3501 - accuracy: 0.85 - ETA: 0s - loss: 0.3539 - accuracy: 0.85 - ETA: 0s - loss: 0.3543 - accuracy: 0.85 - ETA: 0s - loss: 0.3541 - accuracy: 0.85 - ETA: 0s - loss: 0.3536 - accuracy: 0.85 - ETA: 0s - loss: 0.3560 - accuracy: 0.85 - ETA: 0s - loss: 0.3544 - accuracy: 0.85 - ETA: 0s - loss: 0.3534 - accuracy: 0.85 - ETA: 0s - loss: 0.3527 - accuracy: 0.85 - ETA: 0s - loss: 0.3520 - accuracy: 0.85 - ETA: 0s - loss: 0.3516 - accuracy: 0.85 - ETA: 0s - loss: 0.3504 - accuracy: 0.85 - 2s 192us/sample - loss: 0.3495 - accuracy: 0.8556 - val_loss: 0.3442 - val_accuracy: 0.8625\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - ETA: 2s - loss: 0.2582 - accuracy: 0.93 - ETA: 1s - loss: 0.3392 - accuracy: 0.86 - ETA: 1s - loss: 0.3318 - accuracy: 0.86 - ETA: 1s - loss: 0.3180 - accuracy: 0.86 - ETA: 1s - loss: 0.3359 - accuracy: 0.85 - ETA: 1s - loss: 0.3414 - accuracy: 0.85 - ETA: 1s - loss: 0.3380 - accuracy: 0.85 - ETA: 1s - loss: 0.3363 - accuracy: 0.85 - ETA: 1s - loss: 0.3404 - accuracy: 0.85 - ETA: 1s - loss: 0.3466 - accuracy: 0.85 - ETA: 0s - loss: 0.3496 - accuracy: 0.85 - ETA: 0s - loss: 0.3492 - accuracy: 0.85 - ETA: 0s - loss: 0.3462 - accuracy: 0.85 - ETA: 0s - loss: 0.3440 - accuracy: 0.85 - ETA: 0s - loss: 0.3421 - accuracy: 0.85 - ETA: 0s - loss: 0.3435 - accuracy: 0.85 - ETA: 0s - loss: 0.3438 - accuracy: 0.85 - ETA: 0s - loss: 0.3427 - accuracy: 0.85 - ETA: 0s - loss: 0.3409 - accuracy: 0.85 - ETA: 0s - loss: 0.3417 - accuracy: 0.85 - ETA: 0s - loss: 0.3468 - accuracy: 0.85 - ETA: 0s - loss: 0.3470 - accuracy: 0.85 - ETA: 0s - loss: 0.3444 - accuracy: 0.85 - ETA: 0s - loss: 0.3454 - accuracy: 0.85 - ETA: 0s - loss: 0.3474 - accuracy: 0.85 - ETA: 0s - loss: 0.3456 - accuracy: 0.85 - 2s 200us/sample - loss: 0.3458 - accuracy: 0.8580 - val_loss: 0.3405 - val_accuracy: 0.8640\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - ETA: 2:47 - loss: 0.7143 - accuracy: 0.28 - ETA: 14s - loss: 0.6161 - accuracy: 0.7422 - ETA: 8s - loss: 0.5684 - accuracy: 0.768 - ETA: 5s - loss: 0.5360 - accuracy: 0.77 - ETA: 4s - loss: 0.5205 - accuracy: 0.78 - ETA: 3s - loss: 0.4989 - accuracy: 0.79 - ETA: 2s - loss: 0.4837 - accuracy: 0.79 - ETA: 2s - loss: 0.4738 - accuracy: 0.80 - ETA: 2s - loss: 0.4728 - accuracy: 0.79 - ETA: 1s - loss: 0.4708 - accuracy: 0.80 - ETA: 1s - loss: 0.4685 - accuracy: 0.79 - ETA: 1s - loss: 0.4627 - accuracy: 0.80 - ETA: 1s - loss: 0.4564 - accuracy: 0.80 - ETA: 1s - loss: 0.4504 - accuracy: 0.80 - ETA: 0s - loss: 0.4455 - accuracy: 0.80 - ETA: 0s - loss: 0.4433 - accuracy: 0.81 - ETA: 0s - loss: 0.4390 - accuracy: 0.81 - ETA: 0s - loss: 0.4380 - accuracy: 0.81 - ETA: 0s - loss: 0.4373 - accuracy: 0.81 - ETA: 0s - loss: 0.4381 - accuracy: 0.81 - ETA: 0s - loss: 0.4377 - accuracy: 0.81 - ETA: 0s - loss: 0.4382 - accuracy: 0.81 - ETA: 0s - loss: 0.4369 - accuracy: 0.81 - ETA: 0s - loss: 0.4366 - accuracy: 0.81 - 2s 292us/sample - loss: 0.4349 - accuracy: 0.8139 - val_loss: 0.3884 - val_accuracy: 0.8450\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.2942 - accuracy: 0.90 - ETA: 1s - loss: 0.3924 - accuracy: 0.83 - ETA: 1s - loss: 0.4212 - accuracy: 0.81 - ETA: 1s - loss: 0.3885 - accuracy: 0.83 - ETA: 1s - loss: 0.3825 - accuracy: 0.84 - ETA: 1s - loss: 0.3762 - accuracy: 0.84 - ETA: 1s - loss: 0.3810 - accuracy: 0.84 - ETA: 1s - loss: 0.3790 - accuracy: 0.84 - ETA: 1s - loss: 0.3733 - accuracy: 0.84 - ETA: 0s - loss: 0.3805 - accuracy: 0.84 - ETA: 0s - loss: 0.3844 - accuracy: 0.84 - ETA: 0s - loss: 0.3840 - accuracy: 0.84 - ETA: 0s - loss: 0.3816 - accuracy: 0.84 - ETA: 0s - loss: 0.3817 - accuracy: 0.84 - ETA: 0s - loss: 0.3823 - accuracy: 0.84 - ETA: 0s - loss: 0.3821 - accuracy: 0.84 - ETA: 0s - loss: 0.3812 - accuracy: 0.84 - ETA: 0s - loss: 0.3828 - accuracy: 0.84 - ETA: 0s - loss: 0.3824 - accuracy: 0.84 - ETA: 0s - loss: 0.3809 - accuracy: 0.84 - ETA: 0s - loss: 0.3815 - accuracy: 0.84 - ETA: 0s - loss: 0.3795 - accuracy: 0.84 - ETA: 0s - loss: 0.3796 - accuracy: 0.84 - ETA: 0s - loss: 0.3785 - accuracy: 0.84 - ETA: 0s - loss: 0.3776 - accuracy: 0.84 - ETA: 0s - loss: 0.3746 - accuracy: 0.84 - ETA: 0s - loss: 0.3731 - accuracy: 0.84 - 2s 201us/sample - loss: 0.3757 - accuracy: 0.8462 - val_loss: 0.3605 - val_accuracy: 0.8465\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - ETA: 3s - loss: 0.5464 - accuracy: 0.75 - ETA: 1s - loss: 0.3708 - accuracy: 0.84 - ETA: 1s - loss: 0.3796 - accuracy: 0.84 - ETA: 1s - loss: 0.3805 - accuracy: 0.84 - ETA: 0s - loss: 0.3657 - accuracy: 0.85 - ETA: 0s - loss: 0.3698 - accuracy: 0.85 - ETA: 0s - loss: 0.3642 - accuracy: 0.85 - ETA: 0s - loss: 0.3596 - accuracy: 0.85 - ETA: 0s - loss: 0.3515 - accuracy: 0.85 - ETA: 0s - loss: 0.3511 - accuracy: 0.85 - ETA: 0s - loss: 0.3475 - accuracy: 0.86 - ETA: 0s - loss: 0.3504 - accuracy: 0.86 - ETA: 0s - loss: 0.3500 - accuracy: 0.86 - ETA: 0s - loss: 0.3534 - accuracy: 0.85 - ETA: 0s - loss: 0.3534 - accuracy: 0.85 - ETA: 0s - loss: 0.3521 - accuracy: 0.85 - ETA: 0s - loss: 0.3529 - accuracy: 0.85 - ETA: 0s - loss: 0.3542 - accuracy: 0.85 - ETA: 0s - loss: 0.3548 - accuracy: 0.85 - ETA: 0s - loss: 0.3564 - accuracy: 0.85 - ETA: 0s - loss: 0.3561 - accuracy: 0.85 - ETA: 0s - loss: 0.3558 - accuracy: 0.85 - 1s 171us/sample - loss: 0.3557 - accuracy: 0.8559 - val_loss: 0.3453 - val_accuracy: 0.8640\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - ETA: 3s - loss: 0.2174 - accuracy: 0.90 - ETA: 1s - loss: 0.3233 - accuracy: 0.86 - ETA: 1s - loss: 0.3294 - accuracy: 0.87 - ETA: 0s - loss: 0.3497 - accuracy: 0.86 - ETA: 0s - loss: 0.3538 - accuracy: 0.85 - ETA: 0s - loss: 0.3551 - accuracy: 0.85 - ETA: 0s - loss: 0.3526 - accuracy: 0.86 - ETA: 0s - loss: 0.3548 - accuracy: 0.86 - ETA: 0s - loss: 0.3543 - accuracy: 0.86 - ETA: 0s - loss: 0.3531 - accuracy: 0.86 - ETA: 0s - loss: 0.3538 - accuracy: 0.85 - ETA: 0s - loss: 0.3478 - accuracy: 0.86 - ETA: 0s - loss: 0.3501 - accuracy: 0.86 - ETA: 0s - loss: 0.3517 - accuracy: 0.86 - ETA: 0s - loss: 0.3487 - accuracy: 0.86 - ETA: 0s - loss: 0.3516 - accuracy: 0.85 - ETA: 0s - loss: 0.3512 - accuracy: 0.86 - ETA: 0s - loss: 0.3507 - accuracy: 0.85 - ETA: 0s - loss: 0.3501 - accuracy: 0.85 - ETA: 0s - loss: 0.3516 - accuracy: 0.85 - ETA: 0s - loss: 0.3511 - accuracy: 0.85 - ETA: 0s - loss: 0.3498 - accuracy: 0.86 - 1s 172us/sample - loss: 0.3477 - accuracy: 0.8612 - val_loss: 0.3422 - val_accuracy: 0.8625\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - ETA: 3s - loss: 0.3191 - accuracy: 0.81 - ETA: 1s - loss: 0.2942 - accuracy: 0.87 - ETA: 1s - loss: 0.3149 - accuracy: 0.86 - ETA: 1s - loss: 0.3285 - accuracy: 0.86 - ETA: 1s - loss: 0.3259 - accuracy: 0.87 - ETA: 0s - loss: 0.3219 - accuracy: 0.87 - ETA: 0s - loss: 0.3247 - accuracy: 0.87 - ETA: 0s - loss: 0.3225 - accuracy: 0.87 - ETA: 0s - loss: 0.3275 - accuracy: 0.86 - ETA: 0s - loss: 0.3281 - accuracy: 0.87 - ETA: 0s - loss: 0.3285 - accuracy: 0.87 - ETA: 0s - loss: 0.3287 - accuracy: 0.86 - ETA: 0s - loss: 0.3288 - accuracy: 0.86 - ETA: 0s - loss: 0.3299 - accuracy: 0.86 - ETA: 0s - loss: 0.3324 - accuracy: 0.86 - ETA: 0s - loss: 0.3339 - accuracy: 0.86 - ETA: 0s - loss: 0.3360 - accuracy: 0.86 - ETA: 0s - loss: 0.3391 - accuracy: 0.86 - ETA: 0s - loss: 0.3424 - accuracy: 0.85 - ETA: 0s - loss: 0.3433 - accuracy: 0.85 - ETA: 0s - loss: 0.3427 - accuracy: 0.85 - ETA: 0s - loss: 0.3442 - accuracy: 0.85 - ETA: 0s - loss: 0.3457 - accuracy: 0.85 - 1s 174us/sample - loss: 0.3452 - accuracy: 0.8579 - val_loss: 0.3482 - val_accuracy: 0.8550\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - ETA: 2:47 - loss: 0.7438 - accuracy: 0.28 - ETA: 13s - loss: 0.6231 - accuracy: 0.7019 - ETA: 6s - loss: 0.5614 - accuracy: 0.747 - ETA: 4s - loss: 0.5492 - accuracy: 0.74 - ETA: 3s - loss: 0.5254 - accuracy: 0.76 - ETA: 2s - loss: 0.5025 - accuracy: 0.77 - ETA: 2s - loss: 0.4934 - accuracy: 0.77 - ETA: 1s - loss: 0.4807 - accuracy: 0.78 - ETA: 1s - loss: 0.4821 - accuracy: 0.78 - ETA: 1s - loss: 0.4739 - accuracy: 0.79 - ETA: 1s - loss: 0.4664 - accuracy: 0.79 - ETA: 1s - loss: 0.4649 - accuracy: 0.79 - ETA: 0s - loss: 0.4589 - accuracy: 0.79 - ETA: 0s - loss: 0.4588 - accuracy: 0.79 - ETA: 0s - loss: 0.4543 - accuracy: 0.80 - ETA: 0s - loss: 0.4488 - accuracy: 0.80 - ETA: 0s - loss: 0.4471 - accuracy: 0.80 - ETA: 0s - loss: 0.4466 - accuracy: 0.80 - ETA: 0s - loss: 0.4424 - accuracy: 0.80 - ETA: 0s - loss: 0.4384 - accuracy: 0.81 - ETA: 0s - loss: 0.4358 - accuracy: 0.81 - ETA: 0s - loss: 0.4373 - accuracy: 0.81 - 2s 280us/sample - loss: 0.4387 - accuracy: 0.8106 - val_loss: 0.3866 - val_accuracy: 0.8560\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - ETA: 2s - loss: 0.3467 - accuracy: 0.84 - ETA: 1s - loss: 0.3816 - accuracy: 0.85 - ETA: 1s - loss: 0.4024 - accuracy: 0.84 - ETA: 1s - loss: 0.4079 - accuracy: 0.83 - ETA: 0s - loss: 0.3933 - accuracy: 0.84 - ETA: 0s - loss: 0.3910 - accuracy: 0.84 - ETA: 0s - loss: 0.3922 - accuracy: 0.84 - ETA: 0s - loss: 0.3874 - accuracy: 0.84 - ETA: 0s - loss: 0.3869 - accuracy: 0.84 - ETA: 0s - loss: 0.3871 - accuracy: 0.84 - ETA: 0s - loss: 0.3820 - accuracy: 0.84 - ETA: 0s - loss: 0.3817 - accuracy: 0.84 - ETA: 0s - loss: 0.3830 - accuracy: 0.84 - ETA: 0s - loss: 0.3819 - accuracy: 0.84 - ETA: 0s - loss: 0.3826 - accuracy: 0.84 - ETA: 0s - loss: 0.3858 - accuracy: 0.84 - ETA: 0s - loss: 0.3860 - accuracy: 0.84 - ETA: 0s - loss: 0.3828 - accuracy: 0.84 - ETA: 0s - loss: 0.3809 - accuracy: 0.84 - ETA: 0s - loss: 0.3803 - accuracy: 0.84 - ETA: 0s - loss: 0.3788 - accuracy: 0.84 - ETA: 0s - loss: 0.3774 - accuracy: 0.84 - 1s 169us/sample - loss: 0.3746 - accuracy: 0.8444 - val_loss: 0.3563 - val_accuracy: 0.8590\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - ETA: 3s - loss: 0.4275 - accuracy: 0.75 - ETA: 1s - loss: 0.4220 - accuracy: 0.82 - ETA: 1s - loss: 0.3920 - accuracy: 0.82 - ETA: 1s - loss: 0.3788 - accuracy: 0.83 - ETA: 1s - loss: 0.3827 - accuracy: 0.83 - ETA: 0s - loss: 0.3779 - accuracy: 0.84 - ETA: 0s - loss: 0.3716 - accuracy: 0.84 - ETA: 0s - loss: 0.3628 - accuracy: 0.85 - ETA: 0s - loss: 0.3627 - accuracy: 0.84 - ETA: 0s - loss: 0.3551 - accuracy: 0.85 - ETA: 0s - loss: 0.3526 - accuracy: 0.85 - ETA: 0s - loss: 0.3569 - accuracy: 0.85 - ETA: 0s - loss: 0.3612 - accuracy: 0.85 - ETA: 0s - loss: 0.3620 - accuracy: 0.85 - ETA: 0s - loss: 0.3597 - accuracy: 0.85 - ETA: 0s - loss: 0.3582 - accuracy: 0.85 - ETA: 0s - loss: 0.3589 - accuracy: 0.85 - ETA: 0s - loss: 0.3589 - accuracy: 0.85 - ETA: 0s - loss: 0.3581 - accuracy: 0.85 - ETA: 0s - loss: 0.3556 - accuracy: 0.85 - ETA: 0s - loss: 0.3562 - accuracy: 0.85 - ETA: 0s - loss: 0.3557 - accuracy: 0.85 - ETA: 0s - loss: 0.3550 - accuracy: 0.85 - ETA: 0s - loss: 0.3554 - accuracy: 0.85 - ETA: 0s - loss: 0.3548 - accuracy: 0.85 - ETA: 0s - loss: 0.3540 - accuracy: 0.85 - ETA: 0s - loss: 0.3544 - accuracy: 0.85 - ETA: 0s - loss: 0.3548 - accuracy: 0.85 - 2s 218us/sample - loss: 0.3549 - accuracy: 0.8555 - val_loss: 0.3478 - val_accuracy: 0.8600\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - ETA: 2s - loss: 0.4592 - accuracy: 0.81 - ETA: 1s - loss: 0.3852 - accuracy: 0.85 - ETA: 1s - loss: 0.3457 - accuracy: 0.87 - ETA: 1s - loss: 0.3477 - accuracy: 0.86 - ETA: 1s - loss: 0.3662 - accuracy: 0.85 - ETA: 1s - loss: 0.3595 - accuracy: 0.85 - ETA: 1s - loss: 0.3513 - accuracy: 0.85 - ETA: 1s - loss: 0.3654 - accuracy: 0.84 - ETA: 1s - loss: 0.3623 - accuracy: 0.85 - ETA: 1s - loss: 0.3602 - accuracy: 0.85 - ETA: 1s - loss: 0.3597 - accuracy: 0.85 - ETA: 1s - loss: 0.3623 - accuracy: 0.85 - ETA: 0s - loss: 0.3624 - accuracy: 0.85 - ETA: 0s - loss: 0.3645 - accuracy: 0.85 - ETA: 1s - loss: 0.3646 - accuracy: 0.85 - ETA: 1s - loss: 0.3618 - accuracy: 0.85 - ETA: 0s - loss: 0.3571 - accuracy: 0.85 - ETA: 0s - loss: 0.3546 - accuracy: 0.85 - ETA: 0s - loss: 0.3518 - accuracy: 0.85 - ETA: 0s - loss: 0.3478 - accuracy: 0.86 - ETA: 0s - loss: 0.3471 - accuracy: 0.86 - ETA: 0s - loss: 0.3486 - accuracy: 0.85 - ETA: 0s - loss: 0.3507 - accuracy: 0.85 - ETA: 0s - loss: 0.3504 - accuracy: 0.85 - ETA: 0s - loss: 0.3509 - accuracy: 0.85 - ETA: 0s - loss: 0.3496 - accuracy: 0.85 - ETA: 0s - loss: 0.3486 - accuracy: 0.85 - ETA: 0s - loss: 0.3476 - accuracy: 0.85 - 2s 219us/sample - loss: 0.3473 - accuracy: 0.8586 - val_loss: 0.3453 - val_accuracy: 0.8630\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - ETA: 4s - loss: 0.2221 - accuracy: 0.90 - ETA: 2s - loss: 0.3531 - accuracy: 0.86 - ETA: 1s - loss: 0.3380 - accuracy: 0.84 - ETA: 1s - loss: 0.3438 - accuracy: 0.84 - ETA: 1s - loss: 0.3266 - accuracy: 0.86 - ETA: 1s - loss: 0.3280 - accuracy: 0.85 - ETA: 1s - loss: 0.3283 - accuracy: 0.85 - ETA: 1s - loss: 0.3359 - accuracy: 0.85 - ETA: 1s - loss: 0.3355 - accuracy: 0.85 - ETA: 1s - loss: 0.3411 - accuracy: 0.85 - ETA: 1s - loss: 0.3400 - accuracy: 0.85 - ETA: 0s - loss: 0.3440 - accuracy: 0.85 - ETA: 0s - loss: 0.3438 - accuracy: 0.85 - ETA: 0s - loss: 0.3457 - accuracy: 0.85 - ETA: 0s - loss: 0.3485 - accuracy: 0.85 - ETA: 0s - loss: 0.3488 - accuracy: 0.85 - ETA: 0s - loss: 0.3444 - accuracy: 0.85 - ETA: 0s - loss: 0.3422 - accuracy: 0.85 - ETA: 0s - loss: 0.3425 - accuracy: 0.85 - ETA: 0s - loss: 0.3425 - accuracy: 0.85 - ETA: 0s - loss: 0.3436 - accuracy: 0.85 - ETA: 0s - loss: 0.3465 - accuracy: 0.85 - ETA: 0s - loss: 0.3477 - accuracy: 0.85 - ETA: 0s - loss: 0.3466 - accuracy: 0.85 - ETA: 0s - loss: 0.3461 - accuracy: 0.85 - 2s 189us/sample - loss: 0.3453 - accuracy: 0.8579 - val_loss: 0.3463 - val_accuracy: 0.8575\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 5493764fe0b0d5f89c720613ea91bf14</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8636667132377625</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 352</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - ETA: 2:48 - loss: 0.7408 - accuracy: 0.46 - ETA: 11s - loss: 0.6821 - accuracy: 0.5917 - ETA: 7s - loss: 0.6479 - accuracy: 0.666 - ETA: 4s - loss: 0.6188 - accuracy: 0.70 - ETA: 4s - loss: 0.6036 - accuracy: 0.71 - ETA: 3s - loss: 0.5826 - accuracy: 0.73 - ETA: 3s - loss: 0.5743 - accuracy: 0.73 - ETA: 2s - loss: 0.5563 - accuracy: 0.74 - ETA: 2s - loss: 0.5480 - accuracy: 0.75 - ETA: 1s - loss: 0.5297 - accuracy: 0.76 - ETA: 1s - loss: 0.5237 - accuracy: 0.76 - ETA: 1s - loss: 0.5138 - accuracy: 0.77 - ETA: 0s - loss: 0.5056 - accuracy: 0.77 - ETA: 0s - loss: 0.5025 - accuracy: 0.77 - ETA: 0s - loss: 0.4980 - accuracy: 0.77 - ETA: 0s - loss: 0.4943 - accuracy: 0.78 - ETA: 0s - loss: 0.4898 - accuracy: 0.78 - ETA: 0s - loss: 0.4856 - accuracy: 0.78 - ETA: 0s - loss: 0.4809 - accuracy: 0.78 - ETA: 0s - loss: 0.4755 - accuracy: 0.79 - ETA: 0s - loss: 0.4724 - accuracy: 0.79 - ETA: 0s - loss: 0.4686 - accuracy: 0.79 - 2s 278us/sample - loss: 0.4705 - accuracy: 0.7925 - val_loss: 0.4154 - val_accuracy: 0.8230\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.4777 - accuracy: 0.81 - ETA: 0s - loss: 0.4542 - accuracy: 0.79 - ETA: 0s - loss: 0.4401 - accuracy: 0.80 - ETA: 0s - loss: 0.4330 - accuracy: 0.81 - ETA: 0s - loss: 0.4224 - accuracy: 0.81 - ETA: 0s - loss: 0.4278 - accuracy: 0.80 - ETA: 0s - loss: 0.4301 - accuracy: 0.80 - ETA: 0s - loss: 0.4257 - accuracy: 0.81 - ETA: 0s - loss: 0.4226 - accuracy: 0.81 - ETA: 0s - loss: 0.4204 - accuracy: 0.81 - ETA: 0s - loss: 0.4164 - accuracy: 0.81 - ETA: 0s - loss: 0.4169 - accuracy: 0.81 - ETA: 0s - loss: 0.4193 - accuracy: 0.81 - ETA: 0s - loss: 0.4193 - accuracy: 0.81 - ETA: 0s - loss: 0.4165 - accuracy: 0.81 - ETA: 0s - loss: 0.4158 - accuracy: 0.81 - ETA: 0s - loss: 0.4135 - accuracy: 0.81 - ETA: 0s - loss: 0.4126 - accuracy: 0.81 - ETA: 0s - loss: 0.4128 - accuracy: 0.82 - ETA: 0s - loss: 0.4140 - accuracy: 0.81 - ETA: 0s - loss: 0.4126 - accuracy: 0.82 - ETA: 0s - loss: 0.4126 - accuracy: 0.82 - ETA: 0s - loss: 0.4114 - accuracy: 0.82 - ETA: 0s - loss: 0.4111 - accuracy: 0.82 - ETA: 0s - loss: 0.4101 - accuracy: 0.82 - ETA: 0s - loss: 0.4103 - accuracy: 0.82 - ETA: 0s - loss: 0.4092 - accuracy: 0.82 - ETA: 0s - loss: 0.4102 - accuracy: 0.82 - ETA: 0s - loss: 0.4085 - accuracy: 0.82 - 2s 217us/sample - loss: 0.4069 - accuracy: 0.8251 - val_loss: 0.3882 - val_accuracy: 0.8475\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.2520 - accuracy: 0.93 - ETA: 1s - loss: 0.3368 - accuracy: 0.86 - ETA: 1s - loss: 0.3426 - accuracy: 0.86 - ETA: 1s - loss: 0.3492 - accuracy: 0.86 - ETA: 1s - loss: 0.3518 - accuracy: 0.85 - ETA: 1s - loss: 0.3639 - accuracy: 0.85 - ETA: 1s - loss: 0.3671 - accuracy: 0.84 - ETA: 1s - loss: 0.3698 - accuracy: 0.84 - ETA: 1s - loss: 0.3734 - accuracy: 0.84 - ETA: 1s - loss: 0.3735 - accuracy: 0.84 - ETA: 1s - loss: 0.3792 - accuracy: 0.84 - ETA: 0s - loss: 0.3838 - accuracy: 0.83 - ETA: 0s - loss: 0.3898 - accuracy: 0.83 - ETA: 0s - loss: 0.3917 - accuracy: 0.83 - ETA: 0s - loss: 0.3909 - accuracy: 0.83 - ETA: 0s - loss: 0.3893 - accuracy: 0.83 - ETA: 0s - loss: 0.3897 - accuracy: 0.83 - ETA: 0s - loss: 0.3910 - accuracy: 0.83 - ETA: 0s - loss: 0.3887 - accuracy: 0.83 - ETA: 0s - loss: 0.3876 - accuracy: 0.83 - ETA: 0s - loss: 0.3866 - accuracy: 0.83 - ETA: 0s - loss: 0.3848 - accuracy: 0.83 - ETA: 0s - loss: 0.3851 - accuracy: 0.83 - ETA: 0s - loss: 0.3863 - accuracy: 0.83 - ETA: 0s - loss: 0.3828 - accuracy: 0.84 - ETA: 0s - loss: 0.3836 - accuracy: 0.84 - ETA: 0s - loss: 0.3851 - accuracy: 0.83 - ETA: 0s - loss: 0.3831 - accuracy: 0.84 - ETA: 0s - loss: 0.3809 - accuracy: 0.84 - ETA: 0s - loss: 0.3825 - accuracy: 0.84 - ETA: 0s - loss: 0.3817 - accuracy: 0.84 - 2s 223us/sample - loss: 0.3826 - accuracy: 0.8403 - val_loss: 0.3663 - val_accuracy: 0.8585\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - ETA: 2s - loss: 0.5813 - accuracy: 0.75 - ETA: 1s - loss: 0.3923 - accuracy: 0.84 - ETA: 1s - loss: 0.4007 - accuracy: 0.83 - ETA: 1s - loss: 0.3982 - accuracy: 0.83 - ETA: 1s - loss: 0.3874 - accuracy: 0.83 - ETA: 1s - loss: 0.3823 - accuracy: 0.84 - ETA: 1s - loss: 0.3802 - accuracy: 0.84 - ETA: 1s - loss: 0.3774 - accuracy: 0.84 - ETA: 1s - loss: 0.3751 - accuracy: 0.84 - ETA: 0s - loss: 0.3726 - accuracy: 0.84 - ETA: 0s - loss: 0.3732 - accuracy: 0.84 - ETA: 0s - loss: 0.3745 - accuracy: 0.84 - ETA: 0s - loss: 0.3717 - accuracy: 0.84 - ETA: 0s - loss: 0.3722 - accuracy: 0.84 - ETA: 0s - loss: 0.3711 - accuracy: 0.84 - ETA: 0s - loss: 0.3668 - accuracy: 0.84 - ETA: 0s - loss: 0.3679 - accuracy: 0.84 - ETA: 0s - loss: 0.3684 - accuracy: 0.84 - ETA: 0s - loss: 0.3672 - accuracy: 0.84 - ETA: 0s - loss: 0.3675 - accuracy: 0.84 - ETA: 0s - loss: 0.3669 - accuracy: 0.84 - ETA: 0s - loss: 0.3668 - accuracy: 0.84 - ETA: 0s - loss: 0.3635 - accuracy: 0.84 - ETA: 0s - loss: 0.3622 - accuracy: 0.85 - ETA: 0s - loss: 0.3614 - accuracy: 0.85 - ETA: 0s - loss: 0.3603 - accuracy: 0.85 - ETA: 0s - loss: 0.3598 - accuracy: 0.85 - ETA: 0s - loss: 0.3630 - accuracy: 0.85 - ETA: 0s - loss: 0.3653 - accuracy: 0.85 - 2s 207us/sample - loss: 0.3650 - accuracy: 0.8510 - val_loss: 0.3571 - val_accuracy: 0.8565\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.4713 - accuracy: 0.81 - ETA: 1s - loss: 0.3533 - accuracy: 0.85 - ETA: 1s - loss: 0.3601 - accuracy: 0.85 - ETA: 1s - loss: 0.3573 - accuracy: 0.85 - ETA: 0s - loss: 0.3718 - accuracy: 0.84 - ETA: 0s - loss: 0.3600 - accuracy: 0.85 - ETA: 0s - loss: 0.3560 - accuracy: 0.85 - ETA: 0s - loss: 0.3624 - accuracy: 0.84 - ETA: 0s - loss: 0.3659 - accuracy: 0.84 - ETA: 0s - loss: 0.3646 - accuracy: 0.84 - ETA: 0s - loss: 0.3674 - accuracy: 0.84 - ETA: 0s - loss: 0.3669 - accuracy: 0.84 - ETA: 0s - loss: 0.3686 - accuracy: 0.84 - ETA: 0s - loss: 0.3669 - accuracy: 0.84 - ETA: 0s - loss: 0.3643 - accuracy: 0.84 - ETA: 0s - loss: 0.3653 - accuracy: 0.84 - ETA: 0s - loss: 0.3645 - accuracy: 0.85 - ETA: 0s - loss: 0.3640 - accuracy: 0.85 - ETA: 0s - loss: 0.3608 - accuracy: 0.85 - ETA: 0s - loss: 0.3583 - accuracy: 0.85 - ETA: 0s - loss: 0.3570 - accuracy: 0.85 - ETA: 0s - loss: 0.3560 - accuracy: 0.85 - ETA: 0s - loss: 0.3554 - accuracy: 0.85 - ETA: 0s - loss: 0.3546 - accuracy: 0.85 - ETA: 0s - loss: 0.3563 - accuracy: 0.85 - ETA: 0s - loss: 0.3556 - accuracy: 0.85 - ETA: 0s - loss: 0.3558 - accuracy: 0.85 - ETA: 0s - loss: 0.3567 - accuracy: 0.85 - ETA: 0s - loss: 0.3556 - accuracy: 0.85 - ETA: 0s - loss: 0.3559 - accuracy: 0.85 - ETA: 0s - loss: 0.3548 - accuracy: 0.85 - ETA: 0s - loss: 0.3560 - accuracy: 0.85 - 2s 240us/sample - loss: 0.3568 - accuracy: 0.8543 - val_loss: 0.3462 - val_accuracy: 0.8605\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - ETA: 2:52 - loss: 0.8248 - accuracy: 0.25 - ETA: 14s - loss: 0.7354 - accuracy: 0.4453 - ETA: 9s - loss: 0.7020 - accuracy: 0.512 - ETA: 7s - loss: 0.6757 - accuracy: 0.56 - ETA: 6s - loss: 0.6619 - accuracy: 0.59 - ETA: 6s - loss: 0.6534 - accuracy: 0.60 - ETA: 5s - loss: 0.6419 - accuracy: 0.62 - ETA: 4s - loss: 0.6129 - accuracy: 0.67 - ETA: 3s - loss: 0.5951 - accuracy: 0.68 - ETA: 3s - loss: 0.5837 - accuracy: 0.70 - ETA: 3s - loss: 0.5801 - accuracy: 0.70 - ETA: 3s - loss: 0.5660 - accuracy: 0.71 - ETA: 2s - loss: 0.5568 - accuracy: 0.72 - ETA: 2s - loss: 0.5501 - accuracy: 0.73 - ETA: 2s - loss: 0.5388 - accuracy: 0.74 - ETA: 1s - loss: 0.5297 - accuracy: 0.74 - ETA: 1s - loss: 0.5234 - accuracy: 0.75 - ETA: 1s - loss: 0.5158 - accuracy: 0.75 - ETA: 1s - loss: 0.5085 - accuracy: 0.76 - ETA: 1s - loss: 0.5051 - accuracy: 0.76 - ETA: 1s - loss: 0.4993 - accuracy: 0.76 - ETA: 1s - loss: 0.4943 - accuracy: 0.77 - ETA: 0s - loss: 0.4902 - accuracy: 0.77 - ETA: 0s - loss: 0.4899 - accuracy: 0.77 - ETA: 0s - loss: 0.4852 - accuracy: 0.77 - ETA: 0s - loss: 0.4822 - accuracy: 0.77 - ETA: 0s - loss: 0.4820 - accuracy: 0.77 - ETA: 0s - loss: 0.4797 - accuracy: 0.78 - ETA: 0s - loss: 0.4774 - accuracy: 0.78 - ETA: 0s - loss: 0.4754 - accuracy: 0.78 - 3s 329us/sample - loss: 0.4718 - accuracy: 0.7855 - val_loss: 0.4051 - val_accuracy: 0.8270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "8000/8000 [==============================] - ETA: 3s - loss: 0.3621 - accuracy: 0.90 - ETA: 1s - loss: 0.4163 - accuracy: 0.81 - ETA: 0s - loss: 0.4256 - accuracy: 0.80 - ETA: 0s - loss: 0.4195 - accuracy: 0.81 - ETA: 0s - loss: 0.4214 - accuracy: 0.81 - ETA: 0s - loss: 0.4091 - accuracy: 0.82 - ETA: 0s - loss: 0.4112 - accuracy: 0.82 - ETA: 0s - loss: 0.4083 - accuracy: 0.82 - ETA: 0s - loss: 0.4070 - accuracy: 0.82 - ETA: 0s - loss: 0.4029 - accuracy: 0.83 - ETA: 0s - loss: 0.4038 - accuracy: 0.83 - ETA: 0s - loss: 0.4048 - accuracy: 0.82 - ETA: 0s - loss: 0.4015 - accuracy: 0.83 - ETA: 0s - loss: 0.4002 - accuracy: 0.83 - ETA: 0s - loss: 0.3991 - accuracy: 0.83 - ETA: 0s - loss: 0.3991 - accuracy: 0.83 - ETA: 0s - loss: 0.3997 - accuracy: 0.83 - ETA: 0s - loss: 0.3996 - accuracy: 0.83 - 1s 135us/sample - loss: 0.3982 - accuracy: 0.8319 - val_loss: 0.3794 - val_accuracy: 0.8500\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - ETA: 2s - loss: 0.4249 - accuracy: 0.87 - ETA: 0s - loss: 0.3529 - accuracy: 0.86 - ETA: 0s - loss: 0.3644 - accuracy: 0.85 - ETA: 0s - loss: 0.3666 - accuracy: 0.84 - ETA: 0s - loss: 0.3755 - accuracy: 0.84 - ETA: 0s - loss: 0.3801 - accuracy: 0.84 - ETA: 0s - loss: 0.3793 - accuracy: 0.84 - ETA: 0s - loss: 0.3808 - accuracy: 0.84 - ETA: 0s - loss: 0.3781 - accuracy: 0.84 - ETA: 0s - loss: 0.3775 - accuracy: 0.84 - ETA: 0s - loss: 0.3760 - accuracy: 0.84 - ETA: 0s - loss: 0.3798 - accuracy: 0.84 - ETA: 0s - loss: 0.3775 - accuracy: 0.84 - ETA: 0s - loss: 0.3804 - accuracy: 0.84 - ETA: 0s - loss: 0.3787 - accuracy: 0.84 - ETA: 0s - loss: 0.3769 - accuracy: 0.84 - ETA: 0s - loss: 0.3781 - accuracy: 0.84 - ETA: 0s - loss: 0.3771 - accuracy: 0.84 - 1s 133us/sample - loss: 0.3765 - accuracy: 0.8465 - val_loss: 0.3624 - val_accuracy: 0.8585\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - ETA: 2s - loss: 0.2054 - accuracy: 0.93 - ETA: 0s - loss: 0.3563 - accuracy: 0.85 - ETA: 0s - loss: 0.3613 - accuracy: 0.85 - ETA: 0s - loss: 0.3591 - accuracy: 0.85 - ETA: 0s - loss: 0.3631 - accuracy: 0.85 - ETA: 0s - loss: 0.3655 - accuracy: 0.85 - ETA: 0s - loss: 0.3583 - accuracy: 0.85 - ETA: 0s - loss: 0.3617 - accuracy: 0.85 - ETA: 0s - loss: 0.3626 - accuracy: 0.85 - ETA: 0s - loss: 0.3612 - accuracy: 0.85 - ETA: 0s - loss: 0.3654 - accuracy: 0.85 - ETA: 0s - loss: 0.3647 - accuracy: 0.84 - ETA: 0s - loss: 0.3630 - accuracy: 0.85 - ETA: 0s - loss: 0.3624 - accuracy: 0.85 - ETA: 0s - loss: 0.3653 - accuracy: 0.85 - ETA: 0s - loss: 0.3639 - accuracy: 0.85 - ETA: 0s - loss: 0.3631 - accuracy: 0.85 - 1s 128us/sample - loss: 0.3626 - accuracy: 0.8518 - val_loss: 0.3544 - val_accuracy: 0.8590\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - ETA: 3s - loss: 0.4116 - accuracy: 0.84 - ETA: 1s - loss: 0.3516 - accuracy: 0.86 - ETA: 1s - loss: 0.3493 - accuracy: 0.86 - ETA: 1s - loss: 0.3419 - accuracy: 0.86 - ETA: 1s - loss: 0.3499 - accuracy: 0.86 - ETA: 0s - loss: 0.3492 - accuracy: 0.86 - ETA: 0s - loss: 0.3534 - accuracy: 0.85 - ETA: 0s - loss: 0.3588 - accuracy: 0.85 - ETA: 0s - loss: 0.3586 - accuracy: 0.85 - ETA: 0s - loss: 0.3532 - accuracy: 0.85 - ETA: 0s - loss: 0.3572 - accuracy: 0.85 - ETA: 0s - loss: 0.3569 - accuracy: 0.85 - ETA: 0s - loss: 0.3564 - accuracy: 0.85 - ETA: 0s - loss: 0.3571 - accuracy: 0.85 - ETA: 0s - loss: 0.3539 - accuracy: 0.85 - ETA: 0s - loss: 0.3531 - accuracy: 0.85 - ETA: 0s - loss: 0.3563 - accuracy: 0.85 - 1s 130us/sample - loss: 0.3543 - accuracy: 0.8545 - val_loss: 0.3495 - val_accuracy: 0.8580\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - ETA: 2:50 - loss: 0.6481 - accuracy: 0.68 - ETA: 13s - loss: 0.6772 - accuracy: 0.5457 - ETA: 7s - loss: 0.6375 - accuracy: 0.622 - ETA: 4s - loss: 0.6153 - accuracy: 0.66 - ETA: 3s - loss: 0.5772 - accuracy: 0.71 - ETA: 2s - loss: 0.5526 - accuracy: 0.73 - ETA: 1s - loss: 0.5408 - accuracy: 0.74 - ETA: 1s - loss: 0.5325 - accuracy: 0.74 - ETA: 1s - loss: 0.5185 - accuracy: 0.75 - ETA: 1s - loss: 0.5124 - accuracy: 0.76 - ETA: 0s - loss: 0.5024 - accuracy: 0.76 - ETA: 0s - loss: 0.4918 - accuracy: 0.77 - ETA: 0s - loss: 0.4876 - accuracy: 0.77 - ETA: 0s - loss: 0.4847 - accuracy: 0.78 - ETA: 0s - loss: 0.4801 - accuracy: 0.78 - ETA: 0s - loss: 0.4778 - accuracy: 0.78 - ETA: 0s - loss: 0.4746 - accuracy: 0.78 - ETA: 0s - loss: 0.4751 - accuracy: 0.78 - ETA: 0s - loss: 0.4707 - accuracy: 0.78 - 2s 252us/sample - loss: 0.4699 - accuracy: 0.7871 - val_loss: 0.4146 - val_accuracy: 0.8285\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.4374 - accuracy: 0.84 - ETA: 1s - loss: 0.3955 - accuracy: 0.82 - ETA: 1s - loss: 0.3979 - accuracy: 0.83 - ETA: 1s - loss: 0.4023 - accuracy: 0.82 - ETA: 1s - loss: 0.4069 - accuracy: 0.82 - ETA: 1s - loss: 0.4107 - accuracy: 0.82 - ETA: 1s - loss: 0.4079 - accuracy: 0.82 - ETA: 0s - loss: 0.4110 - accuracy: 0.82 - ETA: 0s - loss: 0.4154 - accuracy: 0.82 - ETA: 0s - loss: 0.4208 - accuracy: 0.81 - ETA: 0s - loss: 0.4192 - accuracy: 0.81 - ETA: 0s - loss: 0.4161 - accuracy: 0.82 - ETA: 0s - loss: 0.4157 - accuracy: 0.82 - ETA: 0s - loss: 0.4132 - accuracy: 0.82 - ETA: 0s - loss: 0.4064 - accuracy: 0.82 - ETA: 0s - loss: 0.4057 - accuracy: 0.82 - ETA: 0s - loss: 0.4049 - accuracy: 0.82 - ETA: 0s - loss: 0.4041 - accuracy: 0.82 - ETA: 0s - loss: 0.4040 - accuracy: 0.82 - ETA: 0s - loss: 0.4024 - accuracy: 0.82 - ETA: 0s - loss: 0.4032 - accuracy: 0.82 - 1s 157us/sample - loss: 0.4057 - accuracy: 0.8276 - val_loss: 0.3854 - val_accuracy: 0.8480\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - ETA: 2s - loss: 0.2694 - accuracy: 0.96 - ETA: 1s - loss: 0.3851 - accuracy: 0.83 - ETA: 1s - loss: 0.3906 - accuracy: 0.84 - ETA: 1s - loss: 0.3932 - accuracy: 0.83 - ETA: 0s - loss: 0.3820 - accuracy: 0.84 - ETA: 0s - loss: 0.3795 - accuracy: 0.84 - ETA: 0s - loss: 0.3798 - accuracy: 0.84 - ETA: 0s - loss: 0.3833 - accuracy: 0.84 - ETA: 0s - loss: 0.3858 - accuracy: 0.84 - ETA: 0s - loss: 0.3841 - accuracy: 0.84 - ETA: 0s - loss: 0.3844 - accuracy: 0.84 - ETA: 0s - loss: 0.3843 - accuracy: 0.84 - ETA: 0s - loss: 0.3807 - accuracy: 0.84 - ETA: 0s - loss: 0.3813 - accuracy: 0.84 - ETA: 0s - loss: 0.3810 - accuracy: 0.84 - ETA: 0s - loss: 0.3791 - accuracy: 0.84 - ETA: 0s - loss: 0.3799 - accuracy: 0.84 - 1s 131us/sample - loss: 0.3806 - accuracy: 0.8444 - val_loss: 0.3643 - val_accuracy: 0.8560\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.3916 - accuracy: 0.84 - ETA: 0s - loss: 0.3693 - accuracy: 0.85 - ETA: 0s - loss: 0.3753 - accuracy: 0.85 - ETA: 0s - loss: 0.3780 - accuracy: 0.85 - ETA: 0s - loss: 0.3775 - accuracy: 0.84 - ETA: 0s - loss: 0.3676 - accuracy: 0.85 - ETA: 0s - loss: 0.3649 - accuracy: 0.85 - ETA: 0s - loss: 0.3701 - accuracy: 0.85 - ETA: 0s - loss: 0.3669 - accuracy: 0.85 - ETA: 0s - loss: 0.3722 - accuracy: 0.84 - ETA: 0s - loss: 0.3718 - accuracy: 0.84 - ETA: 0s - loss: 0.3679 - accuracy: 0.85 - ETA: 0s - loss: 0.3646 - accuracy: 0.85 - ETA: 0s - loss: 0.3638 - accuracy: 0.85 - ETA: 0s - loss: 0.3660 - accuracy: 0.85 - ETA: 0s - loss: 0.3628 - accuracy: 0.85 - ETA: 0s - loss: 0.3630 - accuracy: 0.85 - 1s 127us/sample - loss: 0.3641 - accuracy: 0.8515 - val_loss: 0.3597 - val_accuracy: 0.8565\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.3441 - accuracy: 0.84 - ETA: 0s - loss: 0.3568 - accuracy: 0.85 - ETA: 0s - loss: 0.3574 - accuracy: 0.85 - ETA: 0s - loss: 0.3587 - accuracy: 0.85 - ETA: 0s - loss: 0.3486 - accuracy: 0.85 - ETA: 0s - loss: 0.3589 - accuracy: 0.84 - ETA: 0s - loss: 0.3569 - accuracy: 0.84 - ETA: 0s - loss: 0.3521 - accuracy: 0.85 - ETA: 0s - loss: 0.3530 - accuracy: 0.85 - ETA: 0s - loss: 0.3516 - accuracy: 0.85 - ETA: 0s - loss: 0.3556 - accuracy: 0.85 - ETA: 0s - loss: 0.3520 - accuracy: 0.85 - ETA: 0s - loss: 0.3555 - accuracy: 0.85 - ETA: 0s - loss: 0.3564 - accuracy: 0.85 - ETA: 0s - loss: 0.3563 - accuracy: 0.85 - ETA: 0s - loss: 0.3557 - accuracy: 0.85 - ETA: 0s - loss: 0.3558 - accuracy: 0.85 - ETA: 0s - loss: 0.3549 - accuracy: 0.85 - 1s 135us/sample - loss: 0.3559 - accuracy: 0.8550 - val_loss: 0.3483 - val_accuracy: 0.8590\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: d8d286d38a8926212860b11cc94d9197</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.859499990940094</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - ETA: 2:56 - loss: 0.6887 - accuracy: 0.56 - ETA: 12s - loss: 0.5970 - accuracy: 0.7679 - ETA: 7s - loss: 0.5594 - accuracy: 0.780 - ETA: 4s - loss: 0.5375 - accuracy: 0.77 - ETA: 2s - loss: 0.5103 - accuracy: 0.78 - ETA: 2s - loss: 0.4985 - accuracy: 0.79 - ETA: 1s - loss: 0.4908 - accuracy: 0.79 - ETA: 1s - loss: 0.4856 - accuracy: 0.79 - ETA: 1s - loss: 0.4792 - accuracy: 0.79 - ETA: 1s - loss: 0.4741 - accuracy: 0.79 - ETA: 0s - loss: 0.4722 - accuracy: 0.79 - ETA: 0s - loss: 0.4695 - accuracy: 0.79 - ETA: 0s - loss: 0.4647 - accuracy: 0.80 - ETA: 0s - loss: 0.4626 - accuracy: 0.80 - ETA: 0s - loss: 0.4602 - accuracy: 0.80 - ETA: 0s - loss: 0.4538 - accuracy: 0.80 - ETA: 0s - loss: 0.4505 - accuracy: 0.80 - ETA: 0s - loss: 0.4475 - accuracy: 0.80 - 2s 255us/sample - loss: 0.4441 - accuracy: 0.8089 - val_loss: 0.3929 - val_accuracy: 0.8450\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.2798 - accuracy: 0.93 - ETA: 0s - loss: 0.3932 - accuracy: 0.83 - ETA: 0s - loss: 0.3793 - accuracy: 0.84 - ETA: 0s - loss: 0.3921 - accuracy: 0.83 - ETA: 0s - loss: 0.4007 - accuracy: 0.83 - ETA: 0s - loss: 0.4000 - accuracy: 0.83 - ETA: 0s - loss: 0.3935 - accuracy: 0.83 - ETA: 0s - loss: 0.3930 - accuracy: 0.83 - ETA: 0s - loss: 0.3911 - accuracy: 0.83 - ETA: 0s - loss: 0.3918 - accuracy: 0.83 - ETA: 0s - loss: 0.3888 - accuracy: 0.84 - ETA: 0s - loss: 0.3891 - accuracy: 0.84 - ETA: 0s - loss: 0.3877 - accuracy: 0.84 - ETA: 0s - loss: 0.3876 - accuracy: 0.84 - ETA: 0s - loss: 0.3863 - accuracy: 0.84 - ETA: 0s - loss: 0.3853 - accuracy: 0.84 - ETA: 0s - loss: 0.3828 - accuracy: 0.84 - ETA: 0s - loss: 0.3843 - accuracy: 0.84 - 1s 135us/sample - loss: 0.3834 - accuracy: 0.8422 - val_loss: 0.3635 - val_accuracy: 0.8585\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.3789 - accuracy: 0.87 - ETA: 0s - loss: 0.3442 - accuracy: 0.86 - ETA: 0s - loss: 0.3414 - accuracy: 0.86 - ETA: 0s - loss: 0.3576 - accuracy: 0.85 - ETA: 0s - loss: 0.3676 - accuracy: 0.84 - ETA: 0s - loss: 0.3676 - accuracy: 0.84 - ETA: 0s - loss: 0.3653 - accuracy: 0.85 - ETA: 0s - loss: 0.3671 - accuracy: 0.84 - ETA: 0s - loss: 0.3666 - accuracy: 0.85 - ETA: 0s - loss: 0.3684 - accuracy: 0.84 - ETA: 0s - loss: 0.3656 - accuracy: 0.85 - ETA: 0s - loss: 0.3644 - accuracy: 0.85 - ETA: 0s - loss: 0.3610 - accuracy: 0.85 - ETA: 0s - loss: 0.3609 - accuracy: 0.85 - ETA: 0s - loss: 0.3601 - accuracy: 0.85 - ETA: 0s - loss: 0.3594 - accuracy: 0.85 - ETA: 0s - loss: 0.3572 - accuracy: 0.85 - 1s 131us/sample - loss: 0.3590 - accuracy: 0.8547 - val_loss: 0.3474 - val_accuracy: 0.8670\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.3852 - accuracy: 0.87 - ETA: 1s - loss: 0.3306 - accuracy: 0.87 - ETA: 0s - loss: 0.3274 - accuracy: 0.86 - ETA: 0s - loss: 0.3502 - accuracy: 0.86 - ETA: 0s - loss: 0.3495 - accuracy: 0.86 - ETA: 0s - loss: 0.3512 - accuracy: 0.86 - ETA: 0s - loss: 0.3528 - accuracy: 0.85 - ETA: 0s - loss: 0.3459 - accuracy: 0.86 - ETA: 0s - loss: 0.3440 - accuracy: 0.86 - ETA: 0s - loss: 0.3435 - accuracy: 0.86 - ETA: 0s - loss: 0.3493 - accuracy: 0.86 - ETA: 0s - loss: 0.3493 - accuracy: 0.86 - ETA: 0s - loss: 0.3478 - accuracy: 0.85 - ETA: 0s - loss: 0.3496 - accuracy: 0.85 - ETA: 0s - loss: 0.3500 - accuracy: 0.85 - ETA: 0s - loss: 0.3520 - accuracy: 0.85 - ETA: 0s - loss: 0.3508 - accuracy: 0.85 - ETA: 0s - loss: 0.3518 - accuracy: 0.85 - ETA: 0s - loss: 0.3523 - accuracy: 0.85 - ETA: 0s - loss: 0.3515 - accuracy: 0.85 - ETA: 0s - loss: 0.3534 - accuracy: 0.85 - 1s 158us/sample - loss: 0.3521 - accuracy: 0.8568 - val_loss: 0.3465 - val_accuracy: 0.8640\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - ETA: 2s - loss: 0.3261 - accuracy: 0.87 - ETA: 1s - loss: 0.3569 - accuracy: 0.86 - ETA: 1s - loss: 0.3430 - accuracy: 0.87 - ETA: 0s - loss: 0.3357 - accuracy: 0.86 - ETA: 0s - loss: 0.3405 - accuracy: 0.86 - ETA: 0s - loss: 0.3446 - accuracy: 0.86 - ETA: 0s - loss: 0.3375 - accuracy: 0.86 - ETA: 0s - loss: 0.3383 - accuracy: 0.86 - ETA: 0s - loss: 0.3388 - accuracy: 0.86 - ETA: 0s - loss: 0.3423 - accuracy: 0.86 - ETA: 0s - loss: 0.3428 - accuracy: 0.86 - ETA: 0s - loss: 0.3414 - accuracy: 0.86 - ETA: 0s - loss: 0.3464 - accuracy: 0.86 - ETA: 0s - loss: 0.3463 - accuracy: 0.86 - ETA: 0s - loss: 0.3483 - accuracy: 0.86 - ETA: 0s - loss: 0.3504 - accuracy: 0.86 - ETA: 0s - loss: 0.3502 - accuracy: 0.86 - ETA: 0s - loss: 0.3489 - accuracy: 0.85 - ETA: 0s - loss: 0.3465 - accuracy: 0.86 - ETA: 0s - loss: 0.3463 - accuracy: 0.86 - 1s 149us/sample - loss: 0.3475 - accuracy: 0.8601 - val_loss: 0.3452 - val_accuracy: 0.8605\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - ETA: 2:51 - loss: 0.7226 - accuracy: 0.46 - ETA: 11s - loss: 0.6292 - accuracy: 0.6729 - ETA: 6s - loss: 0.5726 - accuracy: 0.741 - ETA: 4s - loss: 0.5477 - accuracy: 0.75 - ETA: 3s - loss: 0.5263 - accuracy: 0.76 - ETA: 2s - loss: 0.5126 - accuracy: 0.77 - ETA: 2s - loss: 0.5091 - accuracy: 0.77 - ETA: 2s - loss: 0.5041 - accuracy: 0.77 - ETA: 2s - loss: 0.5038 - accuracy: 0.77 - ETA: 2s - loss: 0.4979 - accuracy: 0.77 - ETA: 2s - loss: 0.4886 - accuracy: 0.78 - ETA: 1s - loss: 0.4843 - accuracy: 0.78 - ETA: 1s - loss: 0.4815 - accuracy: 0.78 - ETA: 1s - loss: 0.4757 - accuracy: 0.79 - ETA: 1s - loss: 0.4674 - accuracy: 0.79 - ETA: 1s - loss: 0.4625 - accuracy: 0.79 - ETA: 1s - loss: 0.4617 - accuracy: 0.79 - ETA: 1s - loss: 0.4598 - accuracy: 0.79 - ETA: 0s - loss: 0.4571 - accuracy: 0.80 - ETA: 0s - loss: 0.4555 - accuracy: 0.80 - ETA: 0s - loss: 0.4533 - accuracy: 0.80 - ETA: 0s - loss: 0.4522 - accuracy: 0.80 - ETA: 0s - loss: 0.4484 - accuracy: 0.80 - ETA: 0s - loss: 0.4459 - accuracy: 0.80 - ETA: 0s - loss: 0.4436 - accuracy: 0.80 - ETA: 0s - loss: 0.4415 - accuracy: 0.80 - ETA: 0s - loss: 0.4395 - accuracy: 0.80 - ETA: 0s - loss: 0.4404 - accuracy: 0.80 - ETA: 0s - loss: 0.4401 - accuracy: 0.80 - 3s 326us/sample - loss: 0.4389 - accuracy: 0.8098 - val_loss: 0.3917 - val_accuracy: 0.8380\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.3896 - accuracy: 0.90 - ETA: 1s - loss: 0.4561 - accuracy: 0.79 - ETA: 1s - loss: 0.4379 - accuracy: 0.80 - ETA: 1s - loss: 0.4343 - accuracy: 0.80 - ETA: 1s - loss: 0.4097 - accuracy: 0.82 - ETA: 1s - loss: 0.4072 - accuracy: 0.82 - ETA: 1s - loss: 0.3918 - accuracy: 0.83 - ETA: 1s - loss: 0.3988 - accuracy: 0.83 - ETA: 0s - loss: 0.3946 - accuracy: 0.83 - ETA: 1s - loss: 0.3954 - accuracy: 0.83 - ETA: 0s - loss: 0.3976 - accuracy: 0.83 - ETA: 0s - loss: 0.3972 - accuracy: 0.83 - ETA: 0s - loss: 0.3944 - accuracy: 0.83 - ETA: 0s - loss: 0.3932 - accuracy: 0.83 - ETA: 0s - loss: 0.3932 - accuracy: 0.83 - ETA: 0s - loss: 0.3941 - accuracy: 0.83 - ETA: 0s - loss: 0.3938 - accuracy: 0.83 - ETA: 0s - loss: 0.3909 - accuracy: 0.83 - ETA: 0s - loss: 0.3911 - accuracy: 0.83 - ETA: 0s - loss: 0.3902 - accuracy: 0.83 - ETA: 0s - loss: 0.3923 - accuracy: 0.83 - ETA: 0s - loss: 0.3910 - accuracy: 0.83 - ETA: 0s - loss: 0.3903 - accuracy: 0.83 - ETA: 0s - loss: 0.3905 - accuracy: 0.83 - ETA: 0s - loss: 0.3869 - accuracy: 0.84 - ETA: 0s - loss: 0.3851 - accuracy: 0.84 - ETA: 0s - loss: 0.3873 - accuracy: 0.84 - ETA: 0s - loss: 0.3859 - accuracy: 0.84 - ETA: 0s - loss: 0.3850 - accuracy: 0.84 - ETA: 0s - loss: 0.3844 - accuracy: 0.84 - ETA: 0s - loss: 0.3831 - accuracy: 0.84 - ETA: 0s - loss: 0.3828 - accuracy: 0.84 - ETA: 0s - loss: 0.3811 - accuracy: 0.84 - 2s 240us/sample - loss: 0.3813 - accuracy: 0.8432 - val_loss: 0.3618 - val_accuracy: 0.8565\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.4773 - accuracy: 0.84 - ETA: 1s - loss: 0.3434 - accuracy: 0.86 - ETA: 1s - loss: 0.3662 - accuracy: 0.85 - ETA: 1s - loss: 0.3707 - accuracy: 0.85 - ETA: 1s - loss: 0.3817 - accuracy: 0.84 - ETA: 1s - loss: 0.3804 - accuracy: 0.84 - ETA: 1s - loss: 0.3744 - accuracy: 0.84 - ETA: 1s - loss: 0.3743 - accuracy: 0.83 - ETA: 1s - loss: 0.3777 - accuracy: 0.83 - ETA: 1s - loss: 0.3797 - accuracy: 0.83 - ETA: 1s - loss: 0.3803 - accuracy: 0.83 - ETA: 1s - loss: 0.3823 - accuracy: 0.83 - ETA: 1s - loss: 0.3769 - accuracy: 0.83 - ETA: 1s - loss: 0.3730 - accuracy: 0.84 - ETA: 1s - loss: 0.3717 - accuracy: 0.84 - ETA: 0s - loss: 0.3707 - accuracy: 0.84 - ETA: 0s - loss: 0.3717 - accuracy: 0.84 - ETA: 0s - loss: 0.3666 - accuracy: 0.84 - ETA: 0s - loss: 0.3631 - accuracy: 0.84 - ETA: 0s - loss: 0.3617 - accuracy: 0.84 - ETA: 0s - loss: 0.3634 - accuracy: 0.84 - ETA: 0s - loss: 0.3638 - accuracy: 0.84 - ETA: 0s - loss: 0.3624 - accuracy: 0.85 - ETA: 0s - loss: 0.3621 - accuracy: 0.85 - ETA: 0s - loss: 0.3618 - accuracy: 0.85 - ETA: 0s - loss: 0.3620 - accuracy: 0.85 - ETA: 0s - loss: 0.3620 - accuracy: 0.85 - ETA: 0s - loss: 0.3609 - accuracy: 0.85 - ETA: 0s - loss: 0.3602 - accuracy: 0.85 - ETA: 0s - loss: 0.3608 - accuracy: 0.85 - ETA: 0s - loss: 0.3605 - accuracy: 0.85 - ETA: 0s - loss: 0.3597 - accuracy: 0.85 - 2s 238us/sample - loss: 0.3596 - accuracy: 0.8524 - val_loss: 0.3533 - val_accuracy: 0.8565\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.4620 - accuracy: 0.81 - ETA: 1s - loss: 0.4126 - accuracy: 0.84 - ETA: 1s - loss: 0.3776 - accuracy: 0.85 - ETA: 1s - loss: 0.3685 - accuracy: 0.85 - ETA: 1s - loss: 0.3702 - accuracy: 0.85 - ETA: 1s - loss: 0.3674 - accuracy: 0.85 - ETA: 1s - loss: 0.3648 - accuracy: 0.85 - ETA: 1s - loss: 0.3603 - accuracy: 0.85 - ETA: 1s - loss: 0.3617 - accuracy: 0.85 - ETA: 1s - loss: 0.3578 - accuracy: 0.85 - ETA: 1s - loss: 0.3598 - accuracy: 0.85 - ETA: 1s - loss: 0.3574 - accuracy: 0.85 - ETA: 1s - loss: 0.3569 - accuracy: 0.85 - ETA: 1s - loss: 0.3603 - accuracy: 0.85 - ETA: 0s - loss: 0.3574 - accuracy: 0.85 - ETA: 0s - loss: 0.3551 - accuracy: 0.85 - ETA: 0s - loss: 0.3530 - accuracy: 0.85 - ETA: 0s - loss: 0.3541 - accuracy: 0.85 - ETA: 0s - loss: 0.3551 - accuracy: 0.85 - ETA: 0s - loss: 0.3558 - accuracy: 0.85 - ETA: 0s - loss: 0.3566 - accuracy: 0.85 - ETA: 0s - loss: 0.3581 - accuracy: 0.85 - ETA: 0s - loss: 0.3578 - accuracy: 0.85 - ETA: 0s - loss: 0.3529 - accuracy: 0.85 - ETA: 0s - loss: 0.3528 - accuracy: 0.85 - ETA: 0s - loss: 0.3539 - accuracy: 0.85 - ETA: 0s - loss: 0.3541 - accuracy: 0.85 - ETA: 0s - loss: 0.3532 - accuracy: 0.85 - ETA: 0s - loss: 0.3524 - accuracy: 0.85 - ETA: 0s - loss: 0.3509 - accuracy: 0.85 - ETA: 0s - loss: 0.3509 - accuracy: 0.85 - ETA: 0s - loss: 0.3518 - accuracy: 0.85 - ETA: 0s - loss: 0.3532 - accuracy: 0.85 - ETA: 0s - loss: 0.3516 - accuracy: 0.85 - 2s 249us/sample - loss: 0.3515 - accuracy: 0.8568 - val_loss: 0.3488 - val_accuracy: 0.8570\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - ETA: 2s - loss: 0.3427 - accuracy: 0.87 - ETA: 1s - loss: 0.3855 - accuracy: 0.84 - ETA: 1s - loss: 0.3558 - accuracy: 0.85 - ETA: 1s - loss: 0.3439 - accuracy: 0.85 - ETA: 1s - loss: 0.3283 - accuracy: 0.86 - ETA: 1s - loss: 0.3396 - accuracy: 0.86 - ETA: 1s - loss: 0.3417 - accuracy: 0.86 - ETA: 1s - loss: 0.3405 - accuracy: 0.86 - ETA: 1s - loss: 0.3536 - accuracy: 0.85 - ETA: 1s - loss: 0.3534 - accuracy: 0.85 - ETA: 0s - loss: 0.3514 - accuracy: 0.85 - ETA: 0s - loss: 0.3519 - accuracy: 0.85 - ETA: 0s - loss: 0.3516 - accuracy: 0.85 - ETA: 0s - loss: 0.3510 - accuracy: 0.85 - ETA: 0s - loss: 0.3504 - accuracy: 0.85 - ETA: 0s - loss: 0.3486 - accuracy: 0.85 - ETA: 0s - loss: 0.3514 - accuracy: 0.85 - ETA: 0s - loss: 0.3507 - accuracy: 0.85 - ETA: 0s - loss: 0.3507 - accuracy: 0.85 - ETA: 0s - loss: 0.3477 - accuracy: 0.85 - ETA: 0s - loss: 0.3469 - accuracy: 0.85 - ETA: 0s - loss: 0.3455 - accuracy: 0.85 - ETA: 0s - loss: 0.3444 - accuracy: 0.85 - ETA: 0s - loss: 0.3438 - accuracy: 0.85 - ETA: 0s - loss: 0.3428 - accuracy: 0.86 - ETA: 0s - loss: 0.3442 - accuracy: 0.86 - ETA: 0s - loss: 0.3450 - accuracy: 0.86 - ETA: 0s - loss: 0.3467 - accuracy: 0.85 - ETA: 0s - loss: 0.3470 - accuracy: 0.85 - ETA: 0s - loss: 0.3465 - accuracy: 0.85 - ETA: 0s - loss: 0.3468 - accuracy: 0.85 - 2s 233us/sample - loss: 0.3462 - accuracy: 0.8580 - val_loss: 0.3483 - val_accuracy: 0.8600\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - ETA: 2:51 - loss: 0.6302 - accuracy: 0.75 - ETA: 14s - loss: 0.5840 - accuracy: 0.7812 - ETA: 9s - loss: 0.5821 - accuracy: 0.759 - ETA: 6s - loss: 0.5658 - accuracy: 0.75 - ETA: 5s - loss: 0.5415 - accuracy: 0.77 - ETA: 4s - loss: 0.5199 - accuracy: 0.78 - ETA: 3s - loss: 0.5078 - accuracy: 0.78 - ETA: 2s - loss: 0.4959 - accuracy: 0.78 - ETA: 2s - loss: 0.4848 - accuracy: 0.79 - ETA: 2s - loss: 0.4806 - accuracy: 0.79 - ETA: 2s - loss: 0.4750 - accuracy: 0.79 - ETA: 2s - loss: 0.4715 - accuracy: 0.79 - ETA: 1s - loss: 0.4757 - accuracy: 0.79 - ETA: 1s - loss: 0.4750 - accuracy: 0.79 - ETA: 1s - loss: 0.4704 - accuracy: 0.79 - ETA: 1s - loss: 0.4672 - accuracy: 0.79 - ETA: 1s - loss: 0.4637 - accuracy: 0.80 - ETA: 1s - loss: 0.4609 - accuracy: 0.80 - ETA: 1s - loss: 0.4567 - accuracy: 0.80 - ETA: 1s - loss: 0.4532 - accuracy: 0.80 - ETA: 1s - loss: 0.4511 - accuracy: 0.80 - ETA: 0s - loss: 0.4510 - accuracy: 0.80 - ETA: 0s - loss: 0.4513 - accuracy: 0.80 - ETA: 0s - loss: 0.4499 - accuracy: 0.80 - ETA: 0s - loss: 0.4487 - accuracy: 0.80 - ETA: 0s - loss: 0.4474 - accuracy: 0.80 - ETA: 0s - loss: 0.4467 - accuracy: 0.80 - ETA: 0s - loss: 0.4437 - accuracy: 0.80 - ETA: 0s - loss: 0.4433 - accuracy: 0.80 - ETA: 0s - loss: 0.4416 - accuracy: 0.81 - ETA: 0s - loss: 0.4392 - accuracy: 0.81 - 3s 336us/sample - loss: 0.4373 - accuracy: 0.8124 - val_loss: 0.3952 - val_accuracy: 0.8410\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - ETA: 1s - loss: 0.5670 - accuracy: 0.62 - ETA: 1s - loss: 0.4115 - accuracy: 0.80 - ETA: 1s - loss: 0.3825 - accuracy: 0.82 - ETA: 1s - loss: 0.3998 - accuracy: 0.82 - ETA: 1s - loss: 0.3965 - accuracy: 0.82 - ETA: 1s - loss: 0.4071 - accuracy: 0.82 - ETA: 1s - loss: 0.4088 - accuracy: 0.82 - ETA: 1s - loss: 0.4087 - accuracy: 0.82 - ETA: 1s - loss: 0.4030 - accuracy: 0.82 - ETA: 1s - loss: 0.3994 - accuracy: 0.82 - ETA: 0s - loss: 0.3954 - accuracy: 0.83 - ETA: 0s - loss: 0.3987 - accuracy: 0.83 - ETA: 0s - loss: 0.3981 - accuracy: 0.83 - ETA: 0s - loss: 0.3970 - accuracy: 0.83 - ETA: 0s - loss: 0.3959 - accuracy: 0.83 - ETA: 0s - loss: 0.3932 - accuracy: 0.83 - ETA: 0s - loss: 0.3922 - accuracy: 0.83 - ETA: 0s - loss: 0.3913 - accuracy: 0.83 - ETA: 0s - loss: 0.3906 - accuracy: 0.83 - ETA: 0s - loss: 0.3885 - accuracy: 0.84 - ETA: 0s - loss: 0.3877 - accuracy: 0.84 - ETA: 0s - loss: 0.3878 - accuracy: 0.84 - ETA: 0s - loss: 0.3871 - accuracy: 0.84 - ETA: 0s - loss: 0.3853 - accuracy: 0.84 - ETA: 0s - loss: 0.3876 - accuracy: 0.84 - ETA: 0s - loss: 0.3862 - accuracy: 0.84 - ETA: 0s - loss: 0.3832 - accuracy: 0.84 - ETA: 0s - loss: 0.3829 - accuracy: 0.84 - ETA: 0s - loss: 0.3804 - accuracy: 0.84 - 2s 209us/sample - loss: 0.3792 - accuracy: 0.8444 - val_loss: 0.3607 - val_accuracy: 0.8525\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - ETA: 2s - loss: 0.4163 - accuracy: 0.87 - ETA: 1s - loss: 0.3351 - accuracy: 0.87 - ETA: 1s - loss: 0.3273 - accuracy: 0.87 - ETA: 1s - loss: 0.3250 - accuracy: 0.87 - ETA: 0s - loss: 0.3348 - accuracy: 0.87 - ETA: 0s - loss: 0.3467 - accuracy: 0.86 - ETA: 0s - loss: 0.3456 - accuracy: 0.86 - ETA: 0s - loss: 0.3462 - accuracy: 0.86 - ETA: 0s - loss: 0.3459 - accuracy: 0.86 - ETA: 0s - loss: 0.3467 - accuracy: 0.86 - ETA: 0s - loss: 0.3538 - accuracy: 0.85 - ETA: 0s - loss: 0.3572 - accuracy: 0.85 - ETA: 0s - loss: 0.3551 - accuracy: 0.85 - ETA: 0s - loss: 0.3594 - accuracy: 0.85 - ETA: 0s - loss: 0.3611 - accuracy: 0.85 - ETA: 0s - loss: 0.3630 - accuracy: 0.85 - ETA: 0s - loss: 0.3628 - accuracy: 0.85 - ETA: 0s - loss: 0.3601 - accuracy: 0.85 - ETA: 0s - loss: 0.3602 - accuracy: 0.85 - ETA: 0s - loss: 0.3581 - accuracy: 0.85 - ETA: 0s - loss: 0.3546 - accuracy: 0.85 - ETA: 0s - loss: 0.3524 - accuracy: 0.85 - ETA: 0s - loss: 0.3541 - accuracy: 0.85 - ETA: 0s - loss: 0.3565 - accuracy: 0.85 - ETA: 0s - loss: 0.3563 - accuracy: 0.85 - ETA: 0s - loss: 0.3578 - accuracy: 0.85 - ETA: 0s - loss: 0.3586 - accuracy: 0.85 - 2s 195us/sample - loss: 0.3591 - accuracy: 0.8533 - val_loss: 0.3467 - val_accuracy: 0.8660\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - ETA: 2s - loss: 0.3272 - accuracy: 0.90 - ETA: 1s - loss: 0.3451 - accuracy: 0.86 - ETA: 1s - loss: 0.3287 - accuracy: 0.86 - ETA: 1s - loss: 0.3515 - accuracy: 0.85 - ETA: 1s - loss: 0.3487 - accuracy: 0.85 - ETA: 1s - loss: 0.3538 - accuracy: 0.85 - ETA: 1s - loss: 0.3578 - accuracy: 0.85 - ETA: 1s - loss: 0.3536 - accuracy: 0.85 - ETA: 0s - loss: 0.3498 - accuracy: 0.85 - ETA: 0s - loss: 0.3550 - accuracy: 0.85 - ETA: 0s - loss: 0.3544 - accuracy: 0.85 - ETA: 0s - loss: 0.3572 - accuracy: 0.85 - ETA: 0s - loss: 0.3562 - accuracy: 0.85 - ETA: 0s - loss: 0.3536 - accuracy: 0.85 - ETA: 0s - loss: 0.3548 - accuracy: 0.85 - ETA: 0s - loss: 0.3541 - accuracy: 0.85 - ETA: 0s - loss: 0.3523 - accuracy: 0.85 - ETA: 0s - loss: 0.3500 - accuracy: 0.85 - ETA: 0s - loss: 0.3474 - accuracy: 0.85 - ETA: 0s - loss: 0.3499 - accuracy: 0.85 - 1s 154us/sample - loss: 0.3494 - accuracy: 0.8571 - val_loss: 0.3429 - val_accuracy: 0.8685\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - ETA: 3s - loss: 0.4619 - accuracy: 0.81 - ETA: 1s - loss: 0.3059 - accuracy: 0.87 - ETA: 1s - loss: 0.3102 - accuracy: 0.86 - ETA: 1s - loss: 0.3236 - accuracy: 0.86 - ETA: 0s - loss: 0.3182 - accuracy: 0.86 - ETA: 0s - loss: 0.3178 - accuracy: 0.87 - ETA: 0s - loss: 0.3335 - accuracy: 0.86 - ETA: 0s - loss: 0.3348 - accuracy: 0.86 - ETA: 0s - loss: 0.3402 - accuracy: 0.86 - ETA: 0s - loss: 0.3420 - accuracy: 0.86 - ETA: 0s - loss: 0.3426 - accuracy: 0.86 - ETA: 0s - loss: 0.3452 - accuracy: 0.85 - ETA: 0s - loss: 0.3420 - accuracy: 0.86 - ETA: 0s - loss: 0.3465 - accuracy: 0.86 - ETA: 0s - loss: 0.3450 - accuracy: 0.86 - ETA: 0s - loss: 0.3425 - accuracy: 0.86 - ETA: 0s - loss: 0.3430 - accuracy: 0.86 - ETA: 0s - loss: 0.3440 - accuracy: 0.86 - 1s 137us/sample - loss: 0.3461 - accuracy: 0.8589 - val_loss: 0.3528 - val_accuracy: 0.8475\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 36cab31ba3136e55f396974910dbf351</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8651666641235352</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             epochs=5,\n",
    "             validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T19:04:30.331026Z",
     "start_time": "2020-09-15T19:04:29.839066Z"
    }
   },
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-15T19:04:33.206878Z",
     "start_time": "2020-09-15T19:04:33.098459Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Results in my_dir/test_pro</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Objective(name='val_accuracy', direction='max')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 36cab31ba3136e55f396974910dbf351</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8651666641235352</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: e66652c49aaf734becb0b46c1d64fdae</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8636667132377625</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.01</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 320</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 5493764fe0b0d5f89c720613ea91bf14</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8636667132377625</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 352</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: d8d286d38a8926212860b11cc94d9197</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.859499990940094</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 1a6bcac7df851bfb0c8f8e3e92bb5ba8</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8216667175292969</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 224</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
